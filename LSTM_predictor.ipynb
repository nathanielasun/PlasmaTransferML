{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe7b3d1-5e35-4160-8aba-327467e6639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PD.PlasmaDataset import PlasmaDataset\n",
    "from PML.PlasmaModel import PlasmaModel\n",
    "from PML.PMLParameters import PMLParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3877660-dae5-46a9-8097-9b62c550e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT = [0.7, 0.2, 0.1] #train/test/val splits\n",
    "DATA_FRAC = 1 #fraction of files to load data from\n",
    "DATASET_NAME = \"main\"\n",
    "HDF5_DATA_DIR = \"./jtext_data/low_freq\" #data to source hdf5 files from\n",
    "ORG_DATA_DIR = \"./jtext_org\" #directory for exporting data CSVs\n",
    "MODEL_COUNT = 20 #number of models to randomly generate and train\n",
    "MODEL_DIR = \"./models\" #directory to save trained models\n",
    "MODEL_METRICS = \"./models/metrics.json\"\n",
    "FEATS = ['dx', 'dy', 'ip', 'ip_error'] #model features\n",
    "HP_SEARCH = 'random' #hyperparameter search mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ce6538-176d-4b75-bfdd-7a825e70a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize processed data with some dummy training feature data directories for testing (uses dx and dy features)\n",
    "PROCESSED_DATA = {\n",
    "    \"train_norm\"   : f'./jtext_org/train/train-norm-{DATASET_NAME}.csv',\n",
    "    \"train_labels\" : f'./jtext_org/train/train-labels-{DATASET_NAME}.csv',\n",
    "    \"test_norm\"    : f'./jtext_org/test/test-norm-{DATASET_NAME}.csv',\n",
    "    \"test_labels\"  : f'./jtext_org/test/test-labels-{DATASET_NAME}.csv',\n",
    "    \"val_norm\"     : f'./jtext_org/val/val-norm-{DATASET_NAME}.csv',\n",
    "    \"val_labels\"   : f'./jtext_org/val/val-labels-{DATASET_NAME}.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a063378-18a1-4747-9d3b-98ff3888c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#designate feature ranges and static parameters for hyperparameter search\n",
    "#note to current user - grid search is currently borked - don't use (plus not efficient)\n",
    "PARAMETER_RANGES = {\n",
    "    'lr'            : [0.001, 0.01], #learning rate range\n",
    "    'lstm_layers'   : [[200,400], [80,120]], #lstm layer count and hidden size ranges\n",
    "    'linear_layers' : [[100,200], [100,150]], #linear layer count and neuron ranges\n",
    "    'dropout_layers': [[0.05, 0.1]], #dropout layer count and dropout probabilities\n",
    "}\n",
    "STATIC_PARAMETERS = {\n",
    "    'batch_size'       : 16,\n",
    "    'criterion'        : torch.nn.BCEWithLogitsLoss(), #uses binary cross entropy loss\n",
    "    'epochs'           : 40, #number of training epochs/model\n",
    "    'init'             : torch.nn.init.xavier_normal_,\n",
    "    'input_size'       : len(FEATS), #set input size to # of features\n",
    "    'lstm_activation'  : torch.nn.functional.tanh, #LSTM layers activation function\n",
    "    'linear_activation': torch.nn.functional.relu, #Linear layers activation function\n",
    "    'optimizer'        : torch.optim.Adam, #use ADAM optimizer\n",
    "    'output_activation': torch.nn.functional.sigmoid, #output neuron activation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6cbd47-38c8-4649-8f4c-24e676289e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(dataset:\"PlasmaDataset\", split:list, features:list, frac:float=1, preview=False):\n",
    "    dataset.initialize() #creates train/test/val subdatasets\n",
    "    dataset.sourceFiles(data_split = split, data_frac = frac) #initialize split/datafrac and gather hdf5 file info\n",
    "    dataset.sourceData(features) #source specified feature data from files\n",
    "    dataset.calcStats() #calculate data statistics from raw feature data\n",
    "    dataset.normalize() #use data statistics to normalize data\n",
    "    dataset.saveCSV(['train', 'test', 'val', 'stats'], name=DATASET_NAME) #export dataset to model-loadable CSV\n",
    "    if preview:\n",
    "        dataset.preview() #preview datasets\n",
    "    dataset.deleteDatasets() #remove dataset from memory (since saved to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51df6cae-7e5b-458f-8b1f-0f65cab2513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModels(\n",
    "                modeler:\"PlasmaModel\", \n",
    "                processed_data:dict, \n",
    "                parameter_ranges:dict, \n",
    "                static_parameters:dict, \n",
    "                model_count:int, \n",
    "                searchmode:str\n",
    "              ):\n",
    "    modeler.makeHyperparameterSet(\n",
    "                    static_params=static_parameters, \n",
    "                    param_ranges=parameter_ranges, \n",
    "                    count=model_count, \n",
    "                    mode=searchmode\n",
    "    )\n",
    "    modeler.prepareData(processed_data)\n",
    "    modeler.runModelSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e97a930-2ec4-4e6c-b85d-25a16d421b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.00580965963889642, 'lstm_layers': [316, 84], 'linear_layers': [164, 106], 'dropout_layers': [0.055421388733220694]}\n",
      "Epoch [1/40], Training Loss: 0.6952\n",
      "Epoch [1/40], Validation Loss: 0.6398\n",
      "Epoch [2/40], Training Loss: 0.6822\n",
      "Epoch [2/40], Validation Loss: 0.6928\n",
      "Epoch [3/40], Training Loss: 0.6918\n",
      "Epoch [3/40], Validation Loss: 0.6913\n",
      "Epoch [4/40], Training Loss: 0.6706\n",
      "Epoch [4/40], Validation Loss: 0.6895\n",
      "Epoch [5/40], Training Loss: 0.6703\n",
      "Epoch [5/40], Validation Loss: 0.7046\n",
      "Epoch [6/40], Training Loss: 0.6653\n",
      "Epoch [6/40], Validation Loss: 0.7033\n",
      "Epoch [7/40], Training Loss: 0.6517\n",
      "Epoch [7/40], Validation Loss: 0.6880\n",
      "Epoch [8/40], Training Loss: 0.6525\n",
      "Epoch [8/40], Validation Loss: 0.6938\n",
      "Epoch [9/40], Training Loss: 0.6480\n",
      "Epoch [9/40], Validation Loss: 0.6748\n",
      "Epoch [10/40], Training Loss: 0.6518\n",
      "Epoch [10/40], Validation Loss: 0.6854\n",
      "Epoch [11/40], Training Loss: 0.6688\n",
      "Epoch [11/40], Validation Loss: 0.7006\n",
      "Epoch [12/40], Training Loss: 0.6619\n",
      "Epoch [12/40], Validation Loss: 0.6899\n",
      "Epoch [13/40], Training Loss: 0.6605\n",
      "Epoch [13/40], Validation Loss: 0.7009\n",
      "Epoch [14/40], Training Loss: 0.6576\n",
      "Epoch [14/40], Validation Loss: 0.6934\n",
      "Epoch [15/40], Training Loss: 0.6571\n",
      "Epoch [15/40], Validation Loss: 0.7056\n",
      "Epoch [16/40], Training Loss: 0.6633\n",
      "Epoch [16/40], Validation Loss: 0.7095\n",
      "Epoch [17/40], Training Loss: 0.6580\n",
      "Epoch [17/40], Validation Loss: 0.6903\n",
      "Epoch [18/40], Training Loss: 0.6547\n",
      "Epoch [18/40], Validation Loss: 0.6997\n",
      "Epoch [19/40], Training Loss: 0.6504\n",
      "Epoch [19/40], Validation Loss: 0.6806\n",
      "Epoch [20/40], Training Loss: 0.6411\n",
      "Epoch [20/40], Validation Loss: 0.6779\n",
      "Epoch [21/40], Training Loss: 0.6393\n",
      "Epoch [21/40], Validation Loss: 0.6868\n",
      "Epoch [22/40], Training Loss: 0.6405\n",
      "Epoch [22/40], Validation Loss: 0.6658\n",
      "Epoch [23/40], Training Loss: 0.6527\n",
      "Epoch [23/40], Validation Loss: 0.6697\n",
      "Epoch [24/40], Training Loss: 0.6361\n",
      "Epoch [24/40], Validation Loss: 0.6929\n",
      "Epoch [25/40], Training Loss: 0.6624\n",
      "Epoch [25/40], Validation Loss: 0.6686\n",
      "Epoch [26/40], Training Loss: 0.6580\n",
      "Epoch [26/40], Validation Loss: 0.6779\n",
      "Epoch [27/40], Training Loss: 0.6574\n",
      "Epoch [27/40], Validation Loss: 0.6895\n",
      "Epoch [28/40], Training Loss: 0.6629\n",
      "Epoch [28/40], Validation Loss: 0.6934\n",
      "Epoch [29/40], Training Loss: 0.6409\n",
      "Epoch [29/40], Validation Loss: 0.6939\n",
      "Epoch [30/40], Training Loss: 0.6272\n",
      "Epoch [30/40], Validation Loss: 0.6791\n",
      "Epoch [31/40], Training Loss: 0.6429\n",
      "Epoch [31/40], Validation Loss: 0.6577\n",
      "Epoch [32/40], Training Loss: 0.6438\n",
      "Epoch [32/40], Validation Loss: 0.6626\n",
      "Epoch [33/40], Training Loss: 0.6425\n",
      "Epoch [33/40], Validation Loss: 0.6673\n",
      "Epoch [34/40], Training Loss: 0.6436\n",
      "Epoch [34/40], Validation Loss: 0.6813\n",
      "Epoch [35/40], Training Loss: 0.6377\n",
      "Epoch [35/40], Validation Loss: 0.6931\n",
      "Epoch [36/40], Training Loss: 0.6445\n",
      "Epoch [36/40], Validation Loss: 0.6648\n",
      "Epoch [37/40], Training Loss: 0.6470\n",
      "Epoch [37/40], Validation Loss: 0.6458\n",
      "Epoch [38/40], Training Loss: 0.6620\n",
      "Epoch [38/40], Validation Loss: 0.6552\n",
      "Epoch [39/40], Training Loss: 0.6508\n",
      "Epoch [39/40], Validation Loss: 0.6461\n",
      "Epoch [40/40], Training Loss: 0.6484\n",
      "Epoch [40/40], Validation Loss: 0.6611\n",
      "Model loss: 80.0439\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.002007331141646667, 'lstm_layers': [207, 86], 'linear_layers': [195, 149], 'dropout_layers': [0.09504556583219315]}\n",
      "Epoch [1/40], Training Loss: 0.6876\n",
      "Epoch [1/40], Validation Loss: 0.6875\n",
      "Epoch [2/40], Training Loss: 0.6809\n",
      "Epoch [2/40], Validation Loss: 0.6891\n",
      "Epoch [3/40], Training Loss: 0.6808\n",
      "Epoch [3/40], Validation Loss: 0.6864\n",
      "Epoch [4/40], Training Loss: 0.6666\n",
      "Epoch [4/40], Validation Loss: 0.7203\n",
      "Epoch [5/40], Training Loss: 0.6604\n",
      "Epoch [5/40], Validation Loss: 0.6830\n",
      "Epoch [6/40], Training Loss: 0.6551\n",
      "Epoch [6/40], Validation Loss: 0.7067\n",
      "Epoch [7/40], Training Loss: 0.6543\n",
      "Epoch [7/40], Validation Loss: 0.6755\n",
      "Epoch [8/40], Training Loss: 0.6478\n",
      "Epoch [8/40], Validation Loss: 0.6980\n",
      "Epoch [9/40], Training Loss: 0.6725\n",
      "Epoch [9/40], Validation Loss: 0.6977\n",
      "Epoch [10/40], Training Loss: 0.6750\n",
      "Epoch [10/40], Validation Loss: 0.6946\n",
      "Epoch [11/40], Training Loss: 0.6761\n",
      "Epoch [11/40], Validation Loss: 0.6962\n",
      "Epoch [12/40], Training Loss: 0.6766\n",
      "Epoch [12/40], Validation Loss: 0.6995\n",
      "Epoch [13/40], Training Loss: 0.6726\n",
      "Epoch [13/40], Validation Loss: 0.6921\n",
      "Epoch [14/40], Training Loss: 0.6740\n",
      "Epoch [14/40], Validation Loss: 0.6996\n",
      "Epoch [15/40], Training Loss: 0.6705\n",
      "Epoch [15/40], Validation Loss: 0.6947\n",
      "Epoch [16/40], Training Loss: 0.6704\n",
      "Epoch [16/40], Validation Loss: 0.6976\n",
      "Epoch [17/40], Training Loss: 0.6720\n",
      "Epoch [17/40], Validation Loss: 0.6984\n",
      "Epoch [18/40], Training Loss: 0.6718\n",
      "Epoch [18/40], Validation Loss: 0.6935\n",
      "Epoch [19/40], Training Loss: 0.6715\n",
      "Epoch [19/40], Validation Loss: 0.6973\n",
      "Epoch [20/40], Training Loss: 0.6712\n",
      "Epoch [20/40], Validation Loss: 0.6947\n",
      "Epoch [21/40], Training Loss: 0.6727\n",
      "Epoch [21/40], Validation Loss: 0.6958\n",
      "Epoch [22/40], Training Loss: 0.6712\n",
      "Epoch [22/40], Validation Loss: 0.7007\n",
      "Epoch [23/40], Training Loss: 0.6711\n",
      "Epoch [23/40], Validation Loss: 0.6973\n",
      "Epoch [24/40], Training Loss: 0.6705\n",
      "Epoch [24/40], Validation Loss: 0.6984\n",
      "Epoch [25/40], Training Loss: 0.6714\n",
      "Epoch [25/40], Validation Loss: 0.6971\n",
      "Epoch [26/40], Training Loss: 0.6720\n",
      "Epoch [26/40], Validation Loss: 0.6958\n",
      "Epoch [27/40], Training Loss: 0.6739\n",
      "Epoch [27/40], Validation Loss: 0.6969\n",
      "Epoch [28/40], Training Loss: 0.6715\n",
      "Epoch [28/40], Validation Loss: 0.6946\n",
      "Epoch [29/40], Training Loss: 0.6738\n",
      "Epoch [29/40], Validation Loss: 0.6936\n",
      "Epoch [30/40], Training Loss: 0.6707\n",
      "Epoch [30/40], Validation Loss: 0.6992\n",
      "Epoch [31/40], Training Loss: 0.6699\n",
      "Epoch [31/40], Validation Loss: 0.6975\n",
      "Epoch [32/40], Training Loss: 0.6708\n",
      "Epoch [32/40], Validation Loss: 0.6994\n",
      "Epoch [33/40], Training Loss: 0.6717\n",
      "Epoch [33/40], Validation Loss: 0.6996\n",
      "Epoch [34/40], Training Loss: 0.6712\n",
      "Epoch [34/40], Validation Loss: 0.6956\n",
      "Epoch [35/40], Training Loss: 0.6708\n",
      "Epoch [35/40], Validation Loss: 0.6964\n",
      "Epoch [36/40], Training Loss: 0.6706\n",
      "Epoch [36/40], Validation Loss: 0.6962\n",
      "Epoch [37/40], Training Loss: 0.6708\n",
      "Epoch [37/40], Validation Loss: 0.6982\n",
      "Epoch [38/40], Training Loss: 0.6751\n",
      "Epoch [38/40], Validation Loss: 0.6925\n",
      "Epoch [39/40], Training Loss: 0.6687\n",
      "Epoch [39/40], Validation Loss: 0.7105\n",
      "Epoch [40/40], Training Loss: 0.6765\n",
      "Epoch [40/40], Validation Loss: 0.6925\n",
      "Model loss: 79.3470\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.004350400182802632, 'lstm_layers': [258, 112], 'linear_layers': [108, 138], 'dropout_layers': [0.05076441922174093]}\n",
      "Epoch [1/40], Training Loss: 0.6998\n",
      "Epoch [1/40], Validation Loss: 0.6906\n",
      "Epoch [2/40], Training Loss: 0.6743\n",
      "Epoch [2/40], Validation Loss: 0.6761\n",
      "Epoch [3/40], Training Loss: 0.6765\n",
      "Epoch [3/40], Validation Loss: 0.6770\n",
      "Epoch [4/40], Training Loss: 0.6840\n",
      "Epoch [4/40], Validation Loss: 0.7208\n",
      "Epoch [5/40], Training Loss: 0.6922\n",
      "Epoch [5/40], Validation Loss: 0.6910\n",
      "Epoch [6/40], Training Loss: 0.6830\n",
      "Epoch [6/40], Validation Loss: 0.6955\n",
      "Epoch [7/40], Training Loss: 0.6799\n",
      "Epoch [7/40], Validation Loss: 0.6969\n",
      "Epoch [8/40], Training Loss: 0.6796\n",
      "Epoch [8/40], Validation Loss: 0.6934\n",
      "Epoch [9/40], Training Loss: 0.6805\n",
      "Epoch [9/40], Validation Loss: 0.6971\n",
      "Epoch [10/40], Training Loss: 0.6802\n",
      "Epoch [10/40], Validation Loss: 0.6931\n",
      "Epoch [11/40], Training Loss: 0.6797\n",
      "Epoch [11/40], Validation Loss: 0.6948\n",
      "Epoch [12/40], Training Loss: 0.6797\n",
      "Epoch [12/40], Validation Loss: 0.6918\n",
      "Epoch [13/40], Training Loss: 0.6717\n",
      "Epoch [13/40], Validation Loss: 0.6885\n",
      "Epoch [14/40], Training Loss: 0.6667\n",
      "Epoch [14/40], Validation Loss: 0.6655\n",
      "Epoch [15/40], Training Loss: 0.6639\n",
      "Epoch [15/40], Validation Loss: 0.6666\n",
      "Epoch [16/40], Training Loss: 0.6451\n",
      "Epoch [16/40], Validation Loss: 0.6864\n",
      "Epoch [17/40], Training Loss: 0.6360\n",
      "Epoch [17/40], Validation Loss: 0.6755\n",
      "Epoch [18/40], Training Loss: 0.6438\n",
      "Epoch [18/40], Validation Loss: 0.6693\n",
      "Epoch [19/40], Training Loss: 0.6330\n",
      "Epoch [19/40], Validation Loss: 0.6700\n",
      "Epoch [20/40], Training Loss: 0.6417\n",
      "Epoch [20/40], Validation Loss: 0.6614\n",
      "Epoch [21/40], Training Loss: 0.6382\n",
      "Epoch [21/40], Validation Loss: 0.6496\n",
      "Epoch [22/40], Training Loss: 0.6431\n",
      "Epoch [22/40], Validation Loss: 0.6325\n",
      "Epoch [23/40], Training Loss: 0.6618\n",
      "Epoch [23/40], Validation Loss: 0.6610\n",
      "Epoch [24/40], Training Loss: 0.6615\n",
      "Epoch [24/40], Validation Loss: 0.6986\n",
      "Epoch [25/40], Training Loss: 0.6440\n",
      "Epoch [25/40], Validation Loss: 0.6167\n",
      "Epoch [26/40], Training Loss: 0.6335\n",
      "Epoch [26/40], Validation Loss: 0.6435\n",
      "Epoch [27/40], Training Loss: 0.6288\n",
      "Epoch [27/40], Validation Loss: 0.6526\n",
      "Epoch [28/40], Training Loss: 0.6537\n",
      "Epoch [28/40], Validation Loss: 0.6718\n",
      "Epoch [29/40], Training Loss: 0.6579\n",
      "Epoch [29/40], Validation Loss: 0.7056\n",
      "Epoch [30/40], Training Loss: 0.6612\n",
      "Epoch [30/40], Validation Loss: 0.6415\n",
      "Epoch [31/40], Training Loss: 0.6323\n",
      "Epoch [31/40], Validation Loss: 0.6392\n",
      "Epoch [32/40], Training Loss: 0.6347\n",
      "Epoch [32/40], Validation Loss: 0.6548\n",
      "Epoch [33/40], Training Loss: 0.6297\n",
      "Epoch [33/40], Validation Loss: 0.6324\n",
      "Epoch [34/40], Training Loss: 0.6480\n",
      "Epoch [34/40], Validation Loss: 0.6500\n",
      "Epoch [35/40], Training Loss: 0.6759\n",
      "Epoch [35/40], Validation Loss: 0.6473\n",
      "Epoch [36/40], Training Loss: 0.6586\n",
      "Epoch [36/40], Validation Loss: 0.6294\n",
      "Epoch [37/40], Training Loss: 0.6481\n",
      "Epoch [37/40], Validation Loss: 0.6317\n",
      "Epoch [38/40], Training Loss: 0.6546\n",
      "Epoch [38/40], Validation Loss: 0.6123\n",
      "Epoch [39/40], Training Loss: 0.6462\n",
      "Epoch [39/40], Validation Loss: 0.6216\n",
      "Epoch [40/40], Training Loss: 0.6440\n",
      "Epoch [40/40], Validation Loss: 0.6083\n",
      "Model loss: 88.1475\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.008708613848787836, 'lstm_layers': [258, 98], 'linear_layers': [121, 114], 'dropout_layers': [0.08515083274582022]}\n",
      "Epoch [1/40], Training Loss: 0.7360\n",
      "Epoch [1/40], Validation Loss: 0.6908\n",
      "Epoch [2/40], Training Loss: 0.6884\n",
      "Epoch [2/40], Validation Loss: 0.7058\n",
      "Epoch [3/40], Training Loss: 0.6851\n",
      "Epoch [3/40], Validation Loss: 0.7042\n",
      "Epoch [4/40], Training Loss: 0.6821\n",
      "Epoch [4/40], Validation Loss: 0.6917\n",
      "Epoch [5/40], Training Loss: 0.6815\n",
      "Epoch [5/40], Validation Loss: 0.7179\n",
      "Epoch [6/40], Training Loss: 0.6838\n",
      "Epoch [6/40], Validation Loss: 0.6999\n",
      "Epoch [7/40], Training Loss: 0.6787\n",
      "Epoch [7/40], Validation Loss: 0.7031\n",
      "Epoch [8/40], Training Loss: 0.6774\n",
      "Epoch [8/40], Validation Loss: 0.6965\n",
      "Epoch [9/40], Training Loss: 0.6789\n",
      "Epoch [9/40], Validation Loss: 0.7143\n",
      "Epoch [10/40], Training Loss: 0.6794\n",
      "Epoch [10/40], Validation Loss: 0.6977\n",
      "Epoch [11/40], Training Loss: 0.6797\n",
      "Epoch [11/40], Validation Loss: 0.7032\n",
      "Epoch [12/40], Training Loss: 0.6791\n",
      "Epoch [12/40], Validation Loss: 0.6993\n",
      "Epoch [13/40], Training Loss: 0.6759\n",
      "Epoch [13/40], Validation Loss: 0.6997\n",
      "Epoch [14/40], Training Loss: 0.6763\n",
      "Epoch [14/40], Validation Loss: 0.7079\n",
      "Epoch [15/40], Training Loss: 0.6735\n",
      "Epoch [15/40], Validation Loss: 0.7066\n",
      "Epoch [16/40], Training Loss: 0.6814\n",
      "Epoch [16/40], Validation Loss: 0.6985\n",
      "Epoch [17/40], Training Loss: 0.6744\n",
      "Epoch [17/40], Validation Loss: 0.7135\n",
      "Epoch [18/40], Training Loss: 0.6771\n",
      "Epoch [18/40], Validation Loss: 0.7027\n",
      "Epoch [19/40], Training Loss: 0.6754\n",
      "Epoch [19/40], Validation Loss: 0.6998\n",
      "Epoch [20/40], Training Loss: 0.6756\n",
      "Epoch [20/40], Validation Loss: 0.6989\n",
      "Epoch [21/40], Training Loss: 0.6738\n",
      "Epoch [21/40], Validation Loss: 0.7007\n",
      "Epoch [22/40], Training Loss: 0.6737\n",
      "Epoch [22/40], Validation Loss: 0.6982\n",
      "Epoch [23/40], Training Loss: 0.6724\n",
      "Epoch [23/40], Validation Loss: 0.7018\n",
      "Epoch [24/40], Training Loss: 0.6686\n",
      "Epoch [24/40], Validation Loss: 0.6991\n",
      "Epoch [25/40], Training Loss: 0.6721\n",
      "Epoch [25/40], Validation Loss: 0.7005\n",
      "Epoch [26/40], Training Loss: 0.6654\n",
      "Epoch [26/40], Validation Loss: 0.6726\n",
      "Epoch [27/40], Training Loss: 0.6630\n",
      "Epoch [27/40], Validation Loss: 0.6735\n",
      "Epoch [28/40], Training Loss: 0.6578\n",
      "Epoch [28/40], Validation Loss: 0.6764\n",
      "Epoch [29/40], Training Loss: 0.6654\n",
      "Epoch [29/40], Validation Loss: 0.7552\n",
      "Epoch [30/40], Training Loss: 0.6830\n",
      "Epoch [30/40], Validation Loss: 0.6860\n",
      "Epoch [31/40], Training Loss: 0.6703\n",
      "Epoch [31/40], Validation Loss: 0.6616\n",
      "Epoch [32/40], Training Loss: 0.6551\n",
      "Epoch [32/40], Validation Loss: 0.6531\n",
      "Epoch [33/40], Training Loss: 0.6524\n",
      "Epoch [33/40], Validation Loss: 0.6908\n",
      "Epoch [34/40], Training Loss: 0.6856\n",
      "Epoch [34/40], Validation Loss: 0.6940\n",
      "Epoch [35/40], Training Loss: 0.6780\n",
      "Epoch [35/40], Validation Loss: 0.6901\n",
      "Epoch [36/40], Training Loss: 0.6823\n",
      "Epoch [36/40], Validation Loss: 0.6913\n",
      "Epoch [37/40], Training Loss: 0.6799\n",
      "Epoch [37/40], Validation Loss: 0.6926\n",
      "Epoch [38/40], Training Loss: 0.6708\n",
      "Epoch [38/40], Validation Loss: 0.6837\n",
      "Epoch [39/40], Training Loss: 0.6683\n",
      "Epoch [39/40], Validation Loss: 0.7872\n",
      "Epoch [40/40], Training Loss: 0.6994\n",
      "Epoch [40/40], Validation Loss: 0.7022\n",
      "Model loss: 82.6921\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.004250102401425492, 'lstm_layers': [309, 119], 'linear_layers': [128, 136], 'dropout_layers': [0.06970373525231456]}\n",
      "Epoch [1/40], Training Loss: 0.7066\n",
      "Epoch [1/40], Validation Loss: 0.7473\n",
      "Epoch [2/40], Training Loss: 0.6803\n",
      "Epoch [2/40], Validation Loss: 0.6989\n",
      "Epoch [3/40], Training Loss: 0.6783\n",
      "Epoch [3/40], Validation Loss: 0.6981\n",
      "Epoch [4/40], Training Loss: 0.6815\n",
      "Epoch [4/40], Validation Loss: 0.6971\n",
      "Epoch [5/40], Training Loss: 0.6814\n",
      "Epoch [5/40], Validation Loss: 0.6975\n",
      "Epoch [6/40], Training Loss: 0.6817\n",
      "Epoch [6/40], Validation Loss: 0.7034\n",
      "Epoch [7/40], Training Loss: 0.6816\n",
      "Epoch [7/40], Validation Loss: 0.6911\n",
      "Epoch [8/40], Training Loss: 0.6823\n",
      "Epoch [8/40], Validation Loss: 0.6917\n",
      "Epoch [9/40], Training Loss: 0.6790\n",
      "Epoch [9/40], Validation Loss: 0.6949\n",
      "Epoch [10/40], Training Loss: 0.6797\n",
      "Epoch [10/40], Validation Loss: 0.6961\n",
      "Epoch [11/40], Training Loss: 0.6802\n",
      "Epoch [11/40], Validation Loss: 0.6951\n",
      "Epoch [12/40], Training Loss: 0.6784\n",
      "Epoch [12/40], Validation Loss: 0.6966\n",
      "Epoch [13/40], Training Loss: 0.6799\n",
      "Epoch [13/40], Validation Loss: 0.6939\n",
      "Epoch [14/40], Training Loss: 0.6787\n",
      "Epoch [14/40], Validation Loss: 0.6956\n",
      "Epoch [15/40], Training Loss: 0.6786\n",
      "Epoch [15/40], Validation Loss: 0.6950\n",
      "Epoch [16/40], Training Loss: 0.6797\n",
      "Epoch [16/40], Validation Loss: 0.6944\n",
      "Epoch [17/40], Training Loss: 0.6789\n",
      "Epoch [17/40], Validation Loss: 0.6951\n",
      "Epoch [18/40], Training Loss: 0.6784\n",
      "Epoch [18/40], Validation Loss: 0.6972\n",
      "Epoch [19/40], Training Loss: 0.6797\n",
      "Epoch [19/40], Validation Loss: 0.6941\n",
      "Epoch [20/40], Training Loss: 0.6791\n",
      "Epoch [20/40], Validation Loss: 0.6935\n",
      "Epoch [21/40], Training Loss: 0.6793\n",
      "Epoch [21/40], Validation Loss: 0.6944\n",
      "Epoch [22/40], Training Loss: 0.6785\n",
      "Epoch [22/40], Validation Loss: 0.6962\n",
      "Epoch [23/40], Training Loss: 0.6785\n",
      "Epoch [23/40], Validation Loss: 0.6947\n",
      "Epoch [24/40], Training Loss: 0.6814\n",
      "Epoch [24/40], Validation Loss: 0.6857\n",
      "Epoch [25/40], Training Loss: 0.6682\n",
      "Epoch [25/40], Validation Loss: 0.6924\n",
      "Epoch [26/40], Training Loss: 0.6766\n",
      "Epoch [26/40], Validation Loss: 0.6749\n",
      "Epoch [27/40], Training Loss: 0.6656\n",
      "Epoch [27/40], Validation Loss: 0.6756\n",
      "Epoch [28/40], Training Loss: 0.6724\n",
      "Epoch [28/40], Validation Loss: 0.6647\n",
      "Epoch [29/40], Training Loss: 0.6715\n",
      "Epoch [29/40], Validation Loss: 0.6605\n",
      "Epoch [30/40], Training Loss: 0.6534\n",
      "Epoch [30/40], Validation Loss: 0.6628\n",
      "Epoch [31/40], Training Loss: 0.6553\n",
      "Epoch [31/40], Validation Loss: 0.6622\n",
      "Epoch [32/40], Training Loss: 0.6547\n",
      "Epoch [32/40], Validation Loss: 0.6627\n",
      "Epoch [33/40], Training Loss: 0.6510\n",
      "Epoch [33/40], Validation Loss: 0.6673\n",
      "Epoch [34/40], Training Loss: 0.6484\n",
      "Epoch [34/40], Validation Loss: 0.6492\n",
      "Epoch [35/40], Training Loss: 0.6587\n",
      "Epoch [35/40], Validation Loss: 0.6776\n",
      "Epoch [36/40], Training Loss: 0.6474\n",
      "Epoch [36/40], Validation Loss: 0.6730\n",
      "Epoch [37/40], Training Loss: 0.6587\n",
      "Epoch [37/40], Validation Loss: 0.6809\n",
      "Epoch [38/40], Training Loss: 0.6641\n",
      "Epoch [38/40], Validation Loss: 0.6647\n",
      "Epoch [39/40], Training Loss: 0.6628\n",
      "Epoch [39/40], Validation Loss: 0.6746\n",
      "Epoch [40/40], Training Loss: 0.6572\n",
      "Epoch [40/40], Validation Loss: 0.6706\n",
      "Model loss: 79.5209\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.008614085312965385, 'lstm_layers': [228, 81], 'linear_layers': [141, 111], 'dropout_layers': [0.07337846290947653]}\n",
      "Epoch [1/40], Training Loss: 0.7060\n",
      "Epoch [1/40], Validation Loss: 0.6721\n",
      "Epoch [2/40], Training Loss: 0.6405\n",
      "Epoch [2/40], Validation Loss: 0.6938\n",
      "Epoch [3/40], Training Loss: 0.6695\n",
      "Epoch [3/40], Validation Loss: 0.7022\n",
      "Epoch [4/40], Training Loss: 0.6868\n",
      "Epoch [4/40], Validation Loss: 0.7147\n",
      "Epoch [5/40], Training Loss: 0.6876\n",
      "Epoch [5/40], Validation Loss: 0.7114\n",
      "Epoch [6/40], Training Loss: 0.6865\n",
      "Epoch [6/40], Validation Loss: 0.7139\n",
      "Epoch [7/40], Training Loss: 0.6859\n",
      "Epoch [7/40], Validation Loss: 0.6982\n",
      "Epoch [8/40], Training Loss: 0.6804\n",
      "Epoch [8/40], Validation Loss: 0.6934\n",
      "Epoch [9/40], Training Loss: 0.6784\n",
      "Epoch [9/40], Validation Loss: 0.7188\n",
      "Epoch [10/40], Training Loss: 0.6981\n",
      "Epoch [10/40], Validation Loss: 0.6905\n",
      "Epoch [11/40], Training Loss: 0.6843\n",
      "Epoch [11/40], Validation Loss: 0.6905\n",
      "Epoch [12/40], Training Loss: 0.6794\n",
      "Epoch [12/40], Validation Loss: 0.6978\n",
      "Epoch [13/40], Training Loss: 0.6744\n",
      "Epoch [13/40], Validation Loss: 0.6874\n",
      "Epoch [14/40], Training Loss: 0.6655\n",
      "Epoch [14/40], Validation Loss: 0.6732\n",
      "Epoch [15/40], Training Loss: 0.6553\n",
      "Epoch [15/40], Validation Loss: 0.6884\n",
      "Epoch [16/40], Training Loss: 0.6458\n",
      "Epoch [16/40], Validation Loss: 0.6846\n",
      "Epoch [17/40], Training Loss: 0.6375\n",
      "Epoch [17/40], Validation Loss: 0.6650\n",
      "Epoch [18/40], Training Loss: 0.6322\n",
      "Epoch [18/40], Validation Loss: 0.6663\n",
      "Epoch [19/40], Training Loss: 0.6286\n",
      "Epoch [19/40], Validation Loss: 0.6605\n",
      "Epoch [20/40], Training Loss: 0.6225\n",
      "Epoch [20/40], Validation Loss: 0.6677\n",
      "Epoch [21/40], Training Loss: 0.6210\n",
      "Epoch [21/40], Validation Loss: 0.6709\n",
      "Epoch [22/40], Training Loss: 0.6137\n",
      "Epoch [22/40], Validation Loss: 0.6569\n",
      "Epoch [23/40], Training Loss: 0.6272\n",
      "Epoch [23/40], Validation Loss: 0.6519\n",
      "Epoch [24/40], Training Loss: 0.6236\n",
      "Epoch [24/40], Validation Loss: 0.6469\n",
      "Epoch [25/40], Training Loss: 0.6085\n",
      "Epoch [25/40], Validation Loss: 0.6775\n",
      "Epoch [26/40], Training Loss: 0.6082\n",
      "Epoch [26/40], Validation Loss: 0.6794\n",
      "Epoch [27/40], Training Loss: 0.6052\n",
      "Epoch [27/40], Validation Loss: 0.6681\n",
      "Epoch [28/40], Training Loss: 0.6171\n",
      "Epoch [28/40], Validation Loss: 0.6582\n",
      "Epoch [29/40], Training Loss: 0.6068\n",
      "Epoch [29/40], Validation Loss: 0.6567\n",
      "Epoch [30/40], Training Loss: 0.6221\n",
      "Epoch [30/40], Validation Loss: 0.6574\n",
      "Epoch [31/40], Training Loss: 0.6140\n",
      "Epoch [31/40], Validation Loss: 0.6447\n",
      "Epoch [32/40], Training Loss: 0.6033\n",
      "Epoch [32/40], Validation Loss: 0.6465\n",
      "Epoch [33/40], Training Loss: 0.5904\n",
      "Epoch [33/40], Validation Loss: 0.6624\n",
      "Epoch [34/40], Training Loss: 0.5873\n",
      "Epoch [34/40], Validation Loss: 0.6788\n",
      "Epoch [35/40], Training Loss: 0.5855\n",
      "Epoch [35/40], Validation Loss: 0.6805\n",
      "Epoch [36/40], Training Loss: 0.6029\n",
      "Epoch [36/40], Validation Loss: 0.6307\n",
      "Epoch [37/40], Training Loss: 0.5944\n",
      "Epoch [37/40], Validation Loss: 0.6567\n",
      "Epoch [38/40], Training Loss: 0.5828\n",
      "Epoch [38/40], Validation Loss: 0.6360\n",
      "Epoch [39/40], Training Loss: 0.5662\n",
      "Epoch [39/40], Validation Loss: 0.6541\n",
      "Epoch [40/40], Training Loss: 0.6089\n",
      "Epoch [40/40], Validation Loss: 0.6790\n",
      "Model loss: 80.6151\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.004786179373994287, 'lstm_layers': [268, 81], 'linear_layers': [137, 126], 'dropout_layers': [0.06039523686275473]}\n",
      "Epoch [1/40], Training Loss: 0.7047\n",
      "Epoch [1/40], Validation Loss: 0.6880\n",
      "Epoch [2/40], Training Loss: 0.6640\n",
      "Epoch [2/40], Validation Loss: 0.7144\n",
      "Epoch [3/40], Training Loss: 0.6657\n",
      "Epoch [3/40], Validation Loss: 0.6571\n",
      "Epoch [4/40], Training Loss: 0.6436\n",
      "Epoch [4/40], Validation Loss: 0.6738\n",
      "Epoch [5/40], Training Loss: 0.6540\n",
      "Epoch [5/40], Validation Loss: 0.6529\n",
      "Epoch [6/40], Training Loss: 0.6759\n",
      "Epoch [6/40], Validation Loss: 0.7104\n",
      "Epoch [7/40], Training Loss: 0.6765\n",
      "Epoch [7/40], Validation Loss: 0.6989\n",
      "Epoch [8/40], Training Loss: 0.6767\n",
      "Epoch [8/40], Validation Loss: 0.7001\n",
      "Epoch [9/40], Training Loss: 0.6763\n",
      "Epoch [9/40], Validation Loss: 0.7068\n",
      "Epoch [10/40], Training Loss: 0.6779\n",
      "Epoch [10/40], Validation Loss: 0.6940\n",
      "Epoch [11/40], Training Loss: 0.6778\n",
      "Epoch [11/40], Validation Loss: 0.7024\n",
      "Epoch [12/40], Training Loss: 0.6757\n",
      "Epoch [12/40], Validation Loss: 0.6962\n",
      "Epoch [13/40], Training Loss: 0.6791\n",
      "Epoch [13/40], Validation Loss: 0.6940\n",
      "Epoch [14/40], Training Loss: 0.6782\n",
      "Epoch [14/40], Validation Loss: 0.6931\n",
      "Epoch [15/40], Training Loss: 0.6790\n",
      "Epoch [15/40], Validation Loss: 0.6930\n",
      "Epoch [16/40], Training Loss: 0.6776\n",
      "Epoch [16/40], Validation Loss: 0.6973\n",
      "Epoch [17/40], Training Loss: 0.6705\n",
      "Epoch [17/40], Validation Loss: 0.6950\n",
      "Epoch [18/40], Training Loss: 0.6727\n",
      "Epoch [18/40], Validation Loss: 0.7160\n",
      "Epoch [19/40], Training Loss: 0.6804\n",
      "Epoch [19/40], Validation Loss: 0.6902\n",
      "Epoch [20/40], Training Loss: 0.6748\n",
      "Epoch [20/40], Validation Loss: 0.6927\n",
      "Epoch [21/40], Training Loss: 0.6783\n",
      "Epoch [21/40], Validation Loss: 0.6935\n",
      "Epoch [22/40], Training Loss: 0.6737\n",
      "Epoch [22/40], Validation Loss: 0.6932\n",
      "Epoch [23/40], Training Loss: 0.6732\n",
      "Epoch [23/40], Validation Loss: 0.6922\n",
      "Epoch [24/40], Training Loss: 0.6722\n",
      "Epoch [24/40], Validation Loss: 0.6925\n",
      "Epoch [25/40], Training Loss: 0.6727\n",
      "Epoch [25/40], Validation Loss: 0.6954\n",
      "Epoch [26/40], Training Loss: 0.6732\n",
      "Epoch [26/40], Validation Loss: 0.6830\n",
      "Epoch [27/40], Training Loss: 0.6771\n",
      "Epoch [27/40], Validation Loss: 0.6863\n",
      "Epoch [28/40], Training Loss: 0.6700\n",
      "Epoch [28/40], Validation Loss: 0.6890\n",
      "Epoch [29/40], Training Loss: 0.6725\n",
      "Epoch [29/40], Validation Loss: 0.6811\n",
      "Epoch [30/40], Training Loss: 0.6734\n",
      "Epoch [30/40], Validation Loss: 0.6891\n",
      "Epoch [31/40], Training Loss: 0.6719\n",
      "Epoch [31/40], Validation Loss: 0.6848\n",
      "Epoch [32/40], Training Loss: 0.6672\n",
      "Epoch [32/40], Validation Loss: 0.6908\n",
      "Epoch [33/40], Training Loss: 0.6621\n",
      "Epoch [33/40], Validation Loss: 0.6936\n",
      "Epoch [34/40], Training Loss: 0.6593\n",
      "Epoch [34/40], Validation Loss: 0.6933\n",
      "Epoch [35/40], Training Loss: 0.6526\n",
      "Epoch [35/40], Validation Loss: 0.7068\n",
      "Epoch [36/40], Training Loss: 0.6427\n",
      "Epoch [36/40], Validation Loss: 0.6917\n",
      "Epoch [37/40], Training Loss: 0.6447\n",
      "Epoch [37/40], Validation Loss: 0.6812\n",
      "Epoch [38/40], Training Loss: 0.6460\n",
      "Epoch [38/40], Validation Loss: 0.6816\n",
      "Epoch [39/40], Training Loss: 0.6483\n",
      "Epoch [39/40], Validation Loss: 0.6608\n",
      "Epoch [40/40], Training Loss: 0.6527\n",
      "Epoch [40/40], Validation Loss: 0.6666\n",
      "Model loss: 75.9990\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.0063266903210951455, 'lstm_layers': [226, 107], 'linear_layers': [177, 140], 'dropout_layers': [0.07429658902975962]}\n",
      "Epoch [1/40], Training Loss: 0.6741\n",
      "Epoch [1/40], Validation Loss: 0.7456\n",
      "Epoch [2/40], Training Loss: 0.7401\n",
      "Epoch [2/40], Validation Loss: 0.6889\n",
      "Epoch [3/40], Training Loss: 0.6812\n",
      "Epoch [3/40], Validation Loss: 0.6864\n",
      "Epoch [4/40], Training Loss: 0.6858\n",
      "Epoch [4/40], Validation Loss: 0.6925\n",
      "Epoch [5/40], Training Loss: 0.6805\n",
      "Epoch [5/40], Validation Loss: 0.6919\n",
      "Epoch [6/40], Training Loss: 0.6819\n",
      "Epoch [6/40], Validation Loss: 0.6914\n",
      "Epoch [7/40], Training Loss: 0.6801\n",
      "Epoch [7/40], Validation Loss: 0.6912\n",
      "Epoch [8/40], Training Loss: 0.6808\n",
      "Epoch [8/40], Validation Loss: 0.6926\n",
      "Epoch [9/40], Training Loss: 0.6801\n",
      "Epoch [9/40], Validation Loss: 0.6911\n",
      "Epoch [10/40], Training Loss: 0.6777\n",
      "Epoch [10/40], Validation Loss: 0.6982\n",
      "Epoch [11/40], Training Loss: 0.6759\n",
      "Epoch [11/40], Validation Loss: 0.6771\n",
      "Epoch [12/40], Training Loss: 0.6664\n",
      "Epoch [12/40], Validation Loss: 0.6752\n",
      "Epoch [13/40], Training Loss: 0.6412\n",
      "Epoch [13/40], Validation Loss: 0.6769\n",
      "Epoch [14/40], Training Loss: 0.6733\n",
      "Epoch [14/40], Validation Loss: 0.6835\n",
      "Epoch [15/40], Training Loss: 0.6725\n",
      "Epoch [15/40], Validation Loss: 0.6827\n",
      "Epoch [16/40], Training Loss: 0.6630\n",
      "Epoch [16/40], Validation Loss: 0.6999\n",
      "Epoch [17/40], Training Loss: 0.6718\n",
      "Epoch [17/40], Validation Loss: 0.6837\n",
      "Epoch [18/40], Training Loss: 0.6643\n",
      "Epoch [18/40], Validation Loss: 0.7010\n",
      "Epoch [19/40], Training Loss: 0.6677\n",
      "Epoch [19/40], Validation Loss: 0.6817\n",
      "Epoch [20/40], Training Loss: 0.6650\n",
      "Epoch [20/40], Validation Loss: 0.6857\n",
      "Epoch [21/40], Training Loss: 0.6626\n",
      "Epoch [21/40], Validation Loss: 0.6837\n",
      "Epoch [22/40], Training Loss: 0.6669\n",
      "Epoch [22/40], Validation Loss: 0.6843\n",
      "Epoch [23/40], Training Loss: 0.6692\n",
      "Epoch [23/40], Validation Loss: 0.6806\n",
      "Epoch [24/40], Training Loss: 0.6591\n",
      "Epoch [24/40], Validation Loss: 0.6822\n",
      "Epoch [25/40], Training Loss: 0.6540\n",
      "Epoch [25/40], Validation Loss: 0.6817\n",
      "Epoch [26/40], Training Loss: 0.6549\n",
      "Epoch [26/40], Validation Loss: 0.6838\n",
      "Epoch [27/40], Training Loss: 0.6552\n",
      "Epoch [27/40], Validation Loss: 0.6759\n",
      "Epoch [28/40], Training Loss: 0.6581\n",
      "Epoch [28/40], Validation Loss: 0.6790\n",
      "Epoch [29/40], Training Loss: 0.6565\n",
      "Epoch [29/40], Validation Loss: 0.6816\n",
      "Epoch [30/40], Training Loss: 0.6552\n",
      "Epoch [30/40], Validation Loss: 0.6790\n",
      "Epoch [31/40], Training Loss: 0.6534\n",
      "Epoch [31/40], Validation Loss: 0.6788\n",
      "Epoch [32/40], Training Loss: 0.6526\n",
      "Epoch [32/40], Validation Loss: 0.6683\n",
      "Epoch [33/40], Training Loss: 0.6624\n",
      "Epoch [33/40], Validation Loss: 0.6690\n",
      "Epoch [34/40], Training Loss: 0.6535\n",
      "Epoch [34/40], Validation Loss: 0.6859\n",
      "Epoch [35/40], Training Loss: 0.6568\n",
      "Epoch [35/40], Validation Loss: 0.6743\n",
      "Epoch [36/40], Training Loss: 0.6547\n",
      "Epoch [36/40], Validation Loss: 0.6790\n",
      "Epoch [37/40], Training Loss: 0.6585\n",
      "Epoch [37/40], Validation Loss: 0.6769\n",
      "Epoch [38/40], Training Loss: 0.6559\n",
      "Epoch [38/40], Validation Loss: 0.6782\n",
      "Epoch [39/40], Training Loss: 0.6537\n",
      "Epoch [39/40], Validation Loss: 0.6915\n",
      "Epoch [40/40], Training Loss: 0.6518\n",
      "Epoch [40/40], Validation Loss: 0.6764\n",
      "Model loss: 82.2342\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.003105423875234841, 'lstm_layers': [354, 106], 'linear_layers': [133, 136], 'dropout_layers': [0.09383856115804223]}\n",
      "Epoch [1/40], Training Loss: 0.6850\n",
      "Epoch [1/40], Validation Loss: 0.9884\n",
      "Epoch [2/40], Training Loss: 0.7055\n",
      "Epoch [2/40], Validation Loss: 0.6952\n",
      "Epoch [3/40], Training Loss: 0.6794\n",
      "Epoch [3/40], Validation Loss: 0.6920\n",
      "Epoch [4/40], Training Loss: 0.6745\n",
      "Epoch [4/40], Validation Loss: 0.7114\n",
      "Epoch [5/40], Training Loss: 0.6764\n",
      "Epoch [5/40], Validation Loss: 0.7087\n",
      "Epoch [6/40], Training Loss: 0.6732\n",
      "Epoch [6/40], Validation Loss: 0.7149\n",
      "Epoch [7/40], Training Loss: 0.6768\n",
      "Epoch [7/40], Validation Loss: 0.6981\n",
      "Epoch [8/40], Training Loss: 0.6707\n",
      "Epoch [8/40], Validation Loss: 0.7049\n",
      "Epoch [9/40], Training Loss: 0.6681\n",
      "Epoch [9/40], Validation Loss: 0.7085\n",
      "Epoch [10/40], Training Loss: 0.6728\n",
      "Epoch [10/40], Validation Loss: 0.6966\n",
      "Epoch [11/40], Training Loss: 0.6668\n",
      "Epoch [11/40], Validation Loss: 0.7083\n",
      "Epoch [12/40], Training Loss: 0.6591\n",
      "Epoch [12/40], Validation Loss: 0.7093\n",
      "Epoch [13/40], Training Loss: 0.6676\n",
      "Epoch [13/40], Validation Loss: 0.6989\n",
      "Epoch [14/40], Training Loss: 0.6608\n",
      "Epoch [14/40], Validation Loss: 0.7096\n",
      "Epoch [15/40], Training Loss: 0.6596\n",
      "Epoch [15/40], Validation Loss: 0.7116\n",
      "Epoch [16/40], Training Loss: 0.6603\n",
      "Epoch [16/40], Validation Loss: 0.7117\n",
      "Epoch [17/40], Training Loss: 0.6628\n",
      "Epoch [17/40], Validation Loss: 0.6993\n",
      "Epoch [18/40], Training Loss: 0.6613\n",
      "Epoch [18/40], Validation Loss: 0.7059\n",
      "Epoch [19/40], Training Loss: 0.6548\n",
      "Epoch [19/40], Validation Loss: 0.7127\n",
      "Epoch [20/40], Training Loss: 0.6584\n",
      "Epoch [20/40], Validation Loss: 0.7119\n",
      "Epoch [21/40], Training Loss: 0.6557\n",
      "Epoch [21/40], Validation Loss: 0.6998\n",
      "Epoch [22/40], Training Loss: 0.6574\n",
      "Epoch [22/40], Validation Loss: 0.6886\n",
      "Epoch [23/40], Training Loss: 0.6543\n",
      "Epoch [23/40], Validation Loss: 0.6691\n",
      "Epoch [24/40], Training Loss: 0.6560\n",
      "Epoch [24/40], Validation Loss: 0.6696\n",
      "Epoch [25/40], Training Loss: 0.6592\n",
      "Epoch [25/40], Validation Loss: 0.6683\n",
      "Epoch [26/40], Training Loss: 0.6478\n",
      "Epoch [26/40], Validation Loss: 0.6705\n",
      "Epoch [27/40], Training Loss: 0.6434\n",
      "Epoch [27/40], Validation Loss: 0.6598\n",
      "Epoch [28/40], Training Loss: 0.6373\n",
      "Epoch [28/40], Validation Loss: 0.6510\n",
      "Epoch [29/40], Training Loss: 0.6477\n",
      "Epoch [29/40], Validation Loss: 0.6471\n",
      "Epoch [30/40], Training Loss: 0.6391\n",
      "Epoch [30/40], Validation Loss: 0.6688\n",
      "Epoch [31/40], Training Loss: 0.6350\n",
      "Epoch [31/40], Validation Loss: 0.6461\n",
      "Epoch [32/40], Training Loss: 0.6628\n",
      "Epoch [32/40], Validation Loss: 0.6736\n",
      "Epoch [33/40], Training Loss: 0.6865\n",
      "Epoch [33/40], Validation Loss: 0.6864\n",
      "Epoch [34/40], Training Loss: 0.6740\n",
      "Epoch [34/40], Validation Loss: 0.6980\n",
      "Epoch [35/40], Training Loss: 0.6693\n",
      "Epoch [35/40], Validation Loss: 0.6988\n",
      "Epoch [36/40], Training Loss: 0.6672\n",
      "Epoch [36/40], Validation Loss: 0.6934\n",
      "Epoch [37/40], Training Loss: 0.6691\n",
      "Epoch [37/40], Validation Loss: 0.6975\n",
      "Epoch [38/40], Training Loss: 0.6672\n",
      "Epoch [38/40], Validation Loss: 0.6890\n",
      "Epoch [39/40], Training Loss: 0.6690\n",
      "Epoch [39/40], Validation Loss: 0.6933\n",
      "Epoch [40/40], Training Loss: 0.6719\n",
      "Epoch [40/40], Validation Loss: 0.6995\n",
      "Model loss: 77.4716\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.00887050044913492, 'lstm_layers': [287, 94], 'linear_layers': [106, 145], 'dropout_layers': [0.0910277472705088]}\n",
      "Epoch [1/40], Training Loss: 0.6960\n",
      "Epoch [1/40], Validation Loss: 0.7118\n",
      "Epoch [2/40], Training Loss: 0.6274\n",
      "Epoch [2/40], Validation Loss: 0.7817\n",
      "Epoch [3/40], Training Loss: 0.6202\n",
      "Epoch [3/40], Validation Loss: 0.6719\n",
      "Epoch [4/40], Training Loss: 0.6767\n",
      "Epoch [4/40], Validation Loss: 0.6503\n",
      "Epoch [5/40], Training Loss: 0.7070\n",
      "Epoch [5/40], Validation Loss: 0.6975\n",
      "Epoch [6/40], Training Loss: 0.6875\n",
      "Epoch [6/40], Validation Loss: 0.7459\n",
      "Epoch [7/40], Training Loss: 0.6874\n",
      "Epoch [7/40], Validation Loss: 0.6928\n",
      "Epoch [8/40], Training Loss: 0.6808\n",
      "Epoch [8/40], Validation Loss: 0.6924\n",
      "Epoch [9/40], Training Loss: 0.6791\n",
      "Epoch [9/40], Validation Loss: 0.6953\n",
      "Epoch [10/40], Training Loss: 0.6792\n",
      "Epoch [10/40], Validation Loss: 0.6951\n",
      "Epoch [11/40], Training Loss: 0.6797\n",
      "Epoch [11/40], Validation Loss: 0.6951\n",
      "Epoch [12/40], Training Loss: 0.6783\n",
      "Epoch [12/40], Validation Loss: 0.6957\n",
      "Epoch [13/40], Training Loss: 0.6787\n",
      "Epoch [13/40], Validation Loss: 0.6950\n",
      "Epoch [14/40], Training Loss: 0.6800\n",
      "Epoch [14/40], Validation Loss: 0.6948\n",
      "Epoch [15/40], Training Loss: 0.6787\n",
      "Epoch [15/40], Validation Loss: 0.6966\n",
      "Epoch [16/40], Training Loss: 0.6787\n",
      "Epoch [16/40], Validation Loss: 0.6987\n",
      "Epoch [17/40], Training Loss: 0.6802\n",
      "Epoch [17/40], Validation Loss: 0.6959\n",
      "Epoch [18/40], Training Loss: 0.6793\n",
      "Epoch [18/40], Validation Loss: 0.6959\n",
      "Epoch [19/40], Training Loss: 0.6784\n",
      "Epoch [19/40], Validation Loss: 0.6948\n",
      "Epoch [20/40], Training Loss: 0.6786\n",
      "Epoch [20/40], Validation Loss: 0.6950\n",
      "Epoch [21/40], Training Loss: 0.6784\n",
      "Epoch [21/40], Validation Loss: 0.6962\n",
      "Epoch [22/40], Training Loss: 0.6786\n",
      "Epoch [22/40], Validation Loss: 0.6958\n",
      "Epoch [23/40], Training Loss: 0.6785\n",
      "Epoch [23/40], Validation Loss: 0.6951\n",
      "Epoch [24/40], Training Loss: 0.6785\n",
      "Epoch [24/40], Validation Loss: 0.6968\n",
      "Epoch [25/40], Training Loss: 0.7321\n",
      "Epoch [25/40], Validation Loss: 0.6936\n",
      "Epoch [26/40], Training Loss: 0.6809\n",
      "Epoch [26/40], Validation Loss: 0.6961\n",
      "Epoch [27/40], Training Loss: 0.6786\n",
      "Epoch [27/40], Validation Loss: 0.6956\n",
      "Epoch [28/40], Training Loss: 0.6786\n",
      "Epoch [28/40], Validation Loss: 0.6967\n",
      "Epoch [29/40], Training Loss: 0.6786\n",
      "Epoch [29/40], Validation Loss: 0.6978\n",
      "Epoch [30/40], Training Loss: 0.6794\n",
      "Epoch [30/40], Validation Loss: 0.6953\n",
      "Epoch [31/40], Training Loss: 0.6790\n",
      "Epoch [31/40], Validation Loss: 0.6980\n",
      "Epoch [32/40], Training Loss: 0.6790\n",
      "Epoch [32/40], Validation Loss: 0.6970\n",
      "Epoch [33/40], Training Loss: 0.6783\n",
      "Epoch [33/40], Validation Loss: 0.6963\n",
      "Epoch [34/40], Training Loss: 0.6785\n",
      "Epoch [34/40], Validation Loss: 0.6954\n",
      "Epoch [35/40], Training Loss: 0.6787\n",
      "Epoch [35/40], Validation Loss: 0.6948\n",
      "Epoch [36/40], Training Loss: 0.6783\n",
      "Epoch [36/40], Validation Loss: 0.6958\n",
      "Epoch [37/40], Training Loss: 0.6785\n",
      "Epoch [37/40], Validation Loss: 0.6958\n",
      "Epoch [38/40], Training Loss: 0.6787\n",
      "Epoch [38/40], Validation Loss: 0.6957\n",
      "Epoch [39/40], Training Loss: 0.6786\n",
      "Epoch [39/40], Validation Loss: 0.6952\n",
      "Epoch [40/40], Training Loss: 0.6785\n",
      "Epoch [40/40], Validation Loss: 0.6959\n",
      "Model loss: 81.7473\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.004891677451299864, 'lstm_layers': [299, 104], 'linear_layers': [154, 122], 'dropout_layers': [0.05807577795622304]}\n",
      "Epoch [1/40], Training Loss: 0.6939\n",
      "Epoch [1/40], Validation Loss: 0.6885\n",
      "Epoch [2/40], Training Loss: 0.6819\n",
      "Epoch [2/40], Validation Loss: 0.7486\n",
      "Epoch [3/40], Training Loss: 0.6918\n",
      "Epoch [3/40], Validation Loss: 0.6850\n",
      "Epoch [4/40], Training Loss: 0.6710\n",
      "Epoch [4/40], Validation Loss: 0.6956\n",
      "Epoch [5/40], Training Loss: 0.6849\n",
      "Epoch [5/40], Validation Loss: 0.6352\n",
      "Epoch [6/40], Training Loss: 0.6610\n",
      "Epoch [6/40], Validation Loss: 0.6490\n",
      "Epoch [7/40], Training Loss: 0.6665\n",
      "Epoch [7/40], Validation Loss: 0.6642\n",
      "Epoch [8/40], Training Loss: 0.6582\n",
      "Epoch [8/40], Validation Loss: 0.6632\n",
      "Epoch [9/40], Training Loss: 0.6573\n",
      "Epoch [9/40], Validation Loss: 0.6677\n",
      "Epoch [10/40], Training Loss: 0.6551\n",
      "Epoch [10/40], Validation Loss: 0.6683\n",
      "Epoch [11/40], Training Loss: 0.6547\n",
      "Epoch [11/40], Validation Loss: 0.6700\n",
      "Epoch [12/40], Training Loss: 0.6636\n",
      "Epoch [12/40], Validation Loss: 0.6630\n",
      "Epoch [13/40], Training Loss: 0.6595\n",
      "Epoch [13/40], Validation Loss: 0.6555\n",
      "Epoch [14/40], Training Loss: 0.6549\n",
      "Epoch [14/40], Validation Loss: 0.6738\n",
      "Epoch [15/40], Training Loss: 0.6538\n",
      "Epoch [15/40], Validation Loss: 0.6751\n",
      "Epoch [16/40], Training Loss: 0.6544\n",
      "Epoch [16/40], Validation Loss: 0.6672\n",
      "Epoch [17/40], Training Loss: 0.6749\n",
      "Epoch [17/40], Validation Loss: 0.6766\n",
      "Epoch [18/40], Training Loss: 0.6788\n",
      "Epoch [18/40], Validation Loss: 0.6760\n",
      "Epoch [19/40], Training Loss: 0.6791\n",
      "Epoch [19/40], Validation Loss: 0.6817\n",
      "Epoch [20/40], Training Loss: 0.6782\n",
      "Epoch [20/40], Validation Loss: 0.6762\n",
      "Epoch [21/40], Training Loss: 0.6737\n",
      "Epoch [21/40], Validation Loss: 0.6824\n",
      "Epoch [22/40], Training Loss: 0.6727\n",
      "Epoch [22/40], Validation Loss: 0.6806\n",
      "Epoch [23/40], Training Loss: 0.6709\n",
      "Epoch [23/40], Validation Loss: 0.6785\n",
      "Epoch [24/40], Training Loss: 0.6752\n",
      "Epoch [24/40], Validation Loss: 0.6766\n",
      "Epoch [25/40], Training Loss: 0.6699\n",
      "Epoch [25/40], Validation Loss: 0.6755\n",
      "Epoch [26/40], Training Loss: 0.6686\n",
      "Epoch [26/40], Validation Loss: 0.6760\n",
      "Epoch [27/40], Training Loss: 0.6685\n",
      "Epoch [27/40], Validation Loss: 0.6770\n",
      "Epoch [28/40], Training Loss: 0.6688\n",
      "Epoch [28/40], Validation Loss: 0.6743\n",
      "Epoch [29/40], Training Loss: 0.6684\n",
      "Epoch [29/40], Validation Loss: 0.6754\n",
      "Epoch [30/40], Training Loss: 0.6682\n",
      "Epoch [30/40], Validation Loss: 0.6763\n",
      "Epoch [31/40], Training Loss: 0.6692\n",
      "Epoch [31/40], Validation Loss: 0.6738\n",
      "Epoch [32/40], Training Loss: 0.6684\n",
      "Epoch [32/40], Validation Loss: 0.6776\n",
      "Epoch [33/40], Training Loss: 0.6680\n",
      "Epoch [33/40], Validation Loss: 0.6746\n",
      "Epoch [34/40], Training Loss: 0.6679\n",
      "Epoch [34/40], Validation Loss: 0.6753\n",
      "Epoch [35/40], Training Loss: 0.6680\n",
      "Epoch [35/40], Validation Loss: 0.6755\n",
      "Epoch [36/40], Training Loss: 0.6676\n",
      "Epoch [36/40], Validation Loss: 0.6753\n",
      "Epoch [37/40], Training Loss: 0.6682\n",
      "Epoch [37/40], Validation Loss: 0.6755\n",
      "Epoch [38/40], Training Loss: 0.6678\n",
      "Epoch [38/40], Validation Loss: 0.6763\n",
      "Epoch [39/40], Training Loss: 0.6679\n",
      "Epoch [39/40], Validation Loss: 0.6764\n",
      "Epoch [40/40], Training Loss: 0.6676\n",
      "Epoch [40/40], Validation Loss: 0.6752\n",
      "Model loss: 90.2959\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.006784841246404933, 'lstm_layers': [329, 102], 'linear_layers': [145, 124], 'dropout_layers': [0.0663639926063101]}\n",
      "Epoch [1/40], Training Loss: 0.6894\n",
      "Epoch [1/40], Validation Loss: 0.7028\n",
      "Epoch [2/40], Training Loss: 0.6909\n",
      "Epoch [2/40], Validation Loss: 0.6926\n",
      "Epoch [3/40], Training Loss: 0.6905\n",
      "Epoch [3/40], Validation Loss: 0.6947\n",
      "Epoch [4/40], Training Loss: 0.6800\n",
      "Epoch [4/40], Validation Loss: 0.6912\n",
      "Epoch [5/40], Training Loss: 0.6834\n",
      "Epoch [5/40], Validation Loss: 0.7124\n",
      "Epoch [6/40], Training Loss: 0.6810\n",
      "Epoch [6/40], Validation Loss: 0.6981\n",
      "Epoch [7/40], Training Loss: 0.6839\n",
      "Epoch [7/40], Validation Loss: 0.6912\n",
      "Epoch [8/40], Training Loss: 0.6815\n",
      "Epoch [8/40], Validation Loss: 0.6975\n",
      "Epoch [9/40], Training Loss: 0.6795\n",
      "Epoch [9/40], Validation Loss: 0.6932\n",
      "Epoch [10/40], Training Loss: 0.6792\n",
      "Epoch [10/40], Validation Loss: 0.6983\n",
      "Epoch [11/40], Training Loss: 0.6790\n",
      "Epoch [11/40], Validation Loss: 0.6934\n",
      "Epoch [12/40], Training Loss: 0.6800\n",
      "Epoch [12/40], Validation Loss: 0.6963\n",
      "Epoch [13/40], Training Loss: 0.6791\n",
      "Epoch [13/40], Validation Loss: 0.6936\n",
      "Epoch [14/40], Training Loss: 0.6776\n",
      "Epoch [14/40], Validation Loss: 0.7203\n",
      "Epoch [15/40], Training Loss: 0.6733\n",
      "Epoch [15/40], Validation Loss: 0.7063\n",
      "Epoch [16/40], Training Loss: 0.6654\n",
      "Epoch [16/40], Validation Loss: 0.7137\n",
      "Epoch [17/40], Training Loss: 0.6673\n",
      "Epoch [17/40], Validation Loss: 0.6846\n",
      "Epoch [18/40], Training Loss: 0.6511\n",
      "Epoch [18/40], Validation Loss: 0.7037\n",
      "Epoch [19/40], Training Loss: 0.6575\n",
      "Epoch [19/40], Validation Loss: 0.6607\n",
      "Epoch [20/40], Training Loss: 0.6543\n",
      "Epoch [20/40], Validation Loss: 0.6726\n",
      "Epoch [21/40], Training Loss: 0.6469\n",
      "Epoch [21/40], Validation Loss: 0.6718\n",
      "Epoch [22/40], Training Loss: 0.6587\n",
      "Epoch [22/40], Validation Loss: 0.6394\n",
      "Epoch [23/40], Training Loss: 0.6755\n",
      "Epoch [23/40], Validation Loss: 0.6709\n",
      "Epoch [24/40], Training Loss: 0.6757\n",
      "Epoch [24/40], Validation Loss: 0.6675\n",
      "Epoch [25/40], Training Loss: 0.6703\n",
      "Epoch [25/40], Validation Loss: 0.6638\n",
      "Epoch [26/40], Training Loss: 0.6654\n",
      "Epoch [26/40], Validation Loss: 0.6667\n",
      "Epoch [27/40], Training Loss: 0.6641\n",
      "Epoch [27/40], Validation Loss: 0.6672\n",
      "Epoch [28/40], Training Loss: 0.6686\n",
      "Epoch [28/40], Validation Loss: 0.6676\n",
      "Epoch [29/40], Training Loss: 0.6635\n",
      "Epoch [29/40], Validation Loss: 0.6674\n",
      "Epoch [30/40], Training Loss: 0.6651\n",
      "Epoch [30/40], Validation Loss: 0.6670\n",
      "Epoch [31/40], Training Loss: 0.6650\n",
      "Epoch [31/40], Validation Loss: 0.6681\n",
      "Epoch [32/40], Training Loss: 0.6614\n",
      "Epoch [32/40], Validation Loss: 0.6680\n",
      "Epoch [33/40], Training Loss: 0.6650\n",
      "Epoch [33/40], Validation Loss: 0.6675\n",
      "Epoch [34/40], Training Loss: 0.6680\n",
      "Epoch [34/40], Validation Loss: 0.6673\n",
      "Epoch [35/40], Training Loss: 0.6621\n",
      "Epoch [35/40], Validation Loss: 0.6670\n",
      "Epoch [36/40], Training Loss: 0.6654\n",
      "Epoch [36/40], Validation Loss: 0.6675\n",
      "Epoch [37/40], Training Loss: 0.6648\n",
      "Epoch [37/40], Validation Loss: 0.6689\n",
      "Epoch [38/40], Training Loss: 0.6638\n",
      "Epoch [38/40], Validation Loss: 0.6605\n",
      "Epoch [39/40], Training Loss: 0.6639\n",
      "Epoch [39/40], Validation Loss: 0.6658\n",
      "Epoch [40/40], Training Loss: 0.6635\n",
      "Epoch [40/40], Validation Loss: 0.6606\n",
      "Model loss: 85.0543\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.005140079677269832, 'lstm_layers': [259, 97], 'linear_layers': [154, 105], 'dropout_layers': [0.08089975065281081]}\n",
      "Epoch [1/40], Training Loss: 0.6832\n",
      "Epoch [1/40], Validation Loss: 0.6849\n",
      "Epoch [2/40], Training Loss: 0.6668\n",
      "Epoch [2/40], Validation Loss: 0.7574\n",
      "Epoch [3/40], Training Loss: 0.7054\n",
      "Epoch [3/40], Validation Loss: 0.6901\n",
      "Epoch [4/40], Training Loss: 0.6752\n",
      "Epoch [4/40], Validation Loss: 0.6918\n",
      "Epoch [5/40], Training Loss: 0.6336\n",
      "Epoch [5/40], Validation Loss: 0.6487\n",
      "Epoch [6/40], Training Loss: 0.6267\n",
      "Epoch [6/40], Validation Loss: 0.6633\n",
      "Epoch [7/40], Training Loss: 0.6405\n",
      "Epoch [7/40], Validation Loss: 0.6618\n",
      "Epoch [8/40], Training Loss: 0.6554\n",
      "Epoch [8/40], Validation Loss: 0.6660\n",
      "Epoch [9/40], Training Loss: 0.6518\n",
      "Epoch [9/40], Validation Loss: 0.6656\n",
      "Epoch [10/40], Training Loss: 0.6453\n",
      "Epoch [10/40], Validation Loss: 0.6699\n",
      "Epoch [11/40], Training Loss: 0.6631\n",
      "Epoch [11/40], Validation Loss: 0.6648\n",
      "Epoch [12/40], Training Loss: 0.6497\n",
      "Epoch [12/40], Validation Loss: 0.6696\n",
      "Epoch [13/40], Training Loss: 0.6484\n",
      "Epoch [13/40], Validation Loss: 0.6738\n",
      "Epoch [14/40], Training Loss: 0.6452\n",
      "Epoch [14/40], Validation Loss: 0.6767\n",
      "Epoch [15/40], Training Loss: 0.6452\n",
      "Epoch [15/40], Validation Loss: 0.6814\n",
      "Epoch [16/40], Training Loss: 0.6416\n",
      "Epoch [16/40], Validation Loss: 0.6766\n",
      "Epoch [17/40], Training Loss: 0.6466\n",
      "Epoch [17/40], Validation Loss: 0.6882\n",
      "Epoch [18/40], Training Loss: 0.6364\n",
      "Epoch [18/40], Validation Loss: 0.6970\n",
      "Epoch [19/40], Training Loss: 0.6352\n",
      "Epoch [19/40], Validation Loss: 0.6974\n",
      "Epoch [20/40], Training Loss: 0.6333\n",
      "Epoch [20/40], Validation Loss: 0.7110\n",
      "Epoch [21/40], Training Loss: 0.6359\n",
      "Epoch [21/40], Validation Loss: 0.6755\n",
      "Epoch [22/40], Training Loss: 0.6454\n",
      "Epoch [22/40], Validation Loss: 0.6767\n",
      "Epoch [23/40], Training Loss: 0.6312\n",
      "Epoch [23/40], Validation Loss: 0.6812\n",
      "Epoch [24/40], Training Loss: 0.6382\n",
      "Epoch [24/40], Validation Loss: 0.6805\n",
      "Epoch [25/40], Training Loss: 0.6357\n",
      "Epoch [25/40], Validation Loss: 0.6775\n",
      "Epoch [26/40], Training Loss: 0.6386\n",
      "Epoch [26/40], Validation Loss: 0.6737\n",
      "Epoch [27/40], Training Loss: 0.6354\n",
      "Epoch [27/40], Validation Loss: 0.6909\n",
      "Epoch [28/40], Training Loss: 0.6362\n",
      "Epoch [28/40], Validation Loss: 0.6701\n",
      "Epoch [29/40], Training Loss: 0.6249\n",
      "Epoch [29/40], Validation Loss: 0.7062\n",
      "Epoch [30/40], Training Loss: 0.6369\n",
      "Epoch [30/40], Validation Loss: 0.6711\n",
      "Epoch [31/40], Training Loss: 0.6239\n",
      "Epoch [31/40], Validation Loss: 0.7219\n",
      "Epoch [32/40], Training Loss: 0.6398\n",
      "Epoch [32/40], Validation Loss: 0.7161\n",
      "Epoch [33/40], Training Loss: 0.6615\n",
      "Epoch [33/40], Validation Loss: 0.6818\n",
      "Epoch [34/40], Training Loss: 0.6621\n",
      "Epoch [34/40], Validation Loss: 0.6639\n",
      "Epoch [35/40], Training Loss: 0.6434\n",
      "Epoch [35/40], Validation Loss: 0.6598\n",
      "Epoch [36/40], Training Loss: 0.6369\n",
      "Epoch [36/40], Validation Loss: 0.6604\n",
      "Epoch [37/40], Training Loss: 0.6331\n",
      "Epoch [37/40], Validation Loss: 0.6680\n",
      "Epoch [38/40], Training Loss: 0.6351\n",
      "Epoch [38/40], Validation Loss: 0.6598\n",
      "Epoch [39/40], Training Loss: 0.6388\n",
      "Epoch [39/40], Validation Loss: 0.6587\n",
      "Epoch [40/40], Training Loss: 0.6349\n",
      "Epoch [40/40], Validation Loss: 0.6617\n",
      "Model loss: 78.6780\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.005150346913990033, 'lstm_layers': [365, 93], 'linear_layers': [125, 118], 'dropout_layers': [0.09560450129216884]}\n",
      "Epoch [1/40], Training Loss: 0.6814\n",
      "Epoch [1/40], Validation Loss: 0.6929\n",
      "Epoch [2/40], Training Loss: 0.6863\n",
      "Epoch [2/40], Validation Loss: 0.6944\n",
      "Epoch [3/40], Training Loss: 0.6630\n",
      "Epoch [3/40], Validation Loss: 0.7493\n",
      "Epoch [4/40], Training Loss: 0.6437\n",
      "Epoch [4/40], Validation Loss: 0.6832\n",
      "Epoch [5/40], Training Loss: 0.6573\n",
      "Epoch [5/40], Validation Loss: 0.6804\n",
      "Epoch [6/40], Training Loss: 0.6424\n",
      "Epoch [6/40], Validation Loss: 0.6620\n",
      "Epoch [7/40], Training Loss: 0.6488\n",
      "Epoch [7/40], Validation Loss: 0.6870\n",
      "Epoch [8/40], Training Loss: 0.6514\n",
      "Epoch [8/40], Validation Loss: 0.6818\n",
      "Epoch [9/40], Training Loss: 0.6417\n",
      "Epoch [9/40], Validation Loss: 0.6535\n",
      "Epoch [10/40], Training Loss: 0.6591\n",
      "Epoch [10/40], Validation Loss: 0.6635\n",
      "Epoch [11/40], Training Loss: 0.6535\n",
      "Epoch [11/40], Validation Loss: 0.6680\n",
      "Epoch [12/40], Training Loss: 0.6526\n",
      "Epoch [12/40], Validation Loss: 0.6618\n",
      "Epoch [13/40], Training Loss: 0.6530\n",
      "Epoch [13/40], Validation Loss: 0.6611\n",
      "Epoch [14/40], Training Loss: 0.6546\n",
      "Epoch [14/40], Validation Loss: 0.6605\n",
      "Epoch [15/40], Training Loss: 0.6519\n",
      "Epoch [15/40], Validation Loss: 0.6614\n",
      "Epoch [16/40], Training Loss: 0.6471\n",
      "Epoch [16/40], Validation Loss: 0.6326\n",
      "Epoch [17/40], Training Loss: 0.6462\n",
      "Epoch [17/40], Validation Loss: 0.6360\n",
      "Epoch [18/40], Training Loss: 0.6510\n",
      "Epoch [18/40], Validation Loss: 0.6358\n",
      "Epoch [19/40], Training Loss: 0.6511\n",
      "Epoch [19/40], Validation Loss: 0.6737\n",
      "Epoch [20/40], Training Loss: 0.6350\n",
      "Epoch [20/40], Validation Loss: 0.6720\n",
      "Epoch [21/40], Training Loss: 0.6498\n",
      "Epoch [21/40], Validation Loss: 0.6913\n",
      "Epoch [22/40], Training Loss: 0.6375\n",
      "Epoch [22/40], Validation Loss: 0.6570\n",
      "Epoch [23/40], Training Loss: 0.6414\n",
      "Epoch [23/40], Validation Loss: 0.6895\n",
      "Epoch [24/40], Training Loss: 0.6775\n",
      "Epoch [24/40], Validation Loss: 0.6946\n",
      "Epoch [25/40], Training Loss: 0.6761\n",
      "Epoch [25/40], Validation Loss: 0.6957\n",
      "Epoch [26/40], Training Loss: 0.6791\n",
      "Epoch [26/40], Validation Loss: 0.6947\n",
      "Epoch [27/40], Training Loss: 0.6790\n",
      "Epoch [27/40], Validation Loss: 0.6836\n",
      "Epoch [28/40], Training Loss: 0.6778\n",
      "Epoch [28/40], Validation Loss: 0.6851\n",
      "Epoch [29/40], Training Loss: 0.6789\n",
      "Epoch [29/40], Validation Loss: 0.6864\n",
      "Epoch [30/40], Training Loss: 0.6781\n",
      "Epoch [30/40], Validation Loss: 0.6851\n",
      "Epoch [31/40], Training Loss: 0.6784\n",
      "Epoch [31/40], Validation Loss: 0.6847\n",
      "Epoch [32/40], Training Loss: 0.6803\n",
      "Epoch [32/40], Validation Loss: 0.6882\n",
      "Epoch [33/40], Training Loss: 0.6774\n",
      "Epoch [33/40], Validation Loss: 0.6854\n",
      "Epoch [34/40], Training Loss: 0.6779\n",
      "Epoch [34/40], Validation Loss: 0.6853\n",
      "Epoch [35/40], Training Loss: 0.6782\n",
      "Epoch [35/40], Validation Loss: 0.6860\n",
      "Epoch [36/40], Training Loss: 0.6782\n",
      "Epoch [36/40], Validation Loss: 0.6838\n",
      "Epoch [37/40], Training Loss: 0.6772\n",
      "Epoch [37/40], Validation Loss: 0.6859\n",
      "Epoch [38/40], Training Loss: 0.6780\n",
      "Epoch [38/40], Validation Loss: 0.6877\n",
      "Epoch [39/40], Training Loss: 0.6783\n",
      "Epoch [39/40], Validation Loss: 0.6858\n",
      "Epoch [40/40], Training Loss: 0.6774\n",
      "Epoch [40/40], Validation Loss: 0.6865\n",
      "Model loss: 82.7670\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.0031699518093019838, 'lstm_layers': [276, 100], 'linear_layers': [140, 132], 'dropout_layers': [0.05092960608339106]}\n",
      "Epoch [1/40], Training Loss: 0.6864\n",
      "Epoch [1/40], Validation Loss: 0.6833\n",
      "Epoch [2/40], Training Loss: 0.6836\n",
      "Epoch [2/40], Validation Loss: 0.6877\n",
      "Epoch [3/40], Training Loss: 0.6827\n",
      "Epoch [3/40], Validation Loss: 0.6732\n",
      "Epoch [4/40], Training Loss: 0.6293\n",
      "Epoch [4/40], Validation Loss: 0.6902\n",
      "Epoch [5/40], Training Loss: 0.7053\n",
      "Epoch [5/40], Validation Loss: 0.6718\n",
      "Epoch [6/40], Training Loss: 0.6534\n",
      "Epoch [6/40], Validation Loss: 0.6560\n",
      "Epoch [7/40], Training Loss: 0.6486\n",
      "Epoch [7/40], Validation Loss: 0.6568\n",
      "Epoch [8/40], Training Loss: 0.6418\n",
      "Epoch [8/40], Validation Loss: 0.6606\n",
      "Epoch [9/40], Training Loss: 0.6336\n",
      "Epoch [9/40], Validation Loss: 0.6578\n",
      "Epoch [10/40], Training Loss: 0.6298\n",
      "Epoch [10/40], Validation Loss: 0.6590\n",
      "Epoch [11/40], Training Loss: 0.6250\n",
      "Epoch [11/40], Validation Loss: 0.6450\n",
      "Epoch [12/40], Training Loss: 0.6276\n",
      "Epoch [12/40], Validation Loss: 0.6569\n",
      "Epoch [13/40], Training Loss: 0.6255\n",
      "Epoch [13/40], Validation Loss: 0.6509\n",
      "Epoch [14/40], Training Loss: 0.6217\n",
      "Epoch [14/40], Validation Loss: 0.6525\n",
      "Epoch [15/40], Training Loss: 0.6240\n",
      "Epoch [15/40], Validation Loss: 0.6379\n",
      "Epoch [16/40], Training Loss: 0.6317\n",
      "Epoch [16/40], Validation Loss: 0.6533\n",
      "Epoch [17/40], Training Loss: 0.6303\n",
      "Epoch [17/40], Validation Loss: 0.6387\n",
      "Epoch [18/40], Training Loss: 0.6353\n",
      "Epoch [18/40], Validation Loss: 0.6630\n",
      "Epoch [19/40], Training Loss: 0.6337\n",
      "Epoch [19/40], Validation Loss: 0.6559\n",
      "Epoch [20/40], Training Loss: 0.6249\n",
      "Epoch [20/40], Validation Loss: 0.6635\n",
      "Epoch [21/40], Training Loss: 0.6395\n",
      "Epoch [21/40], Validation Loss: 0.6675\n",
      "Epoch [22/40], Training Loss: 0.6604\n",
      "Epoch [22/40], Validation Loss: 0.6676\n",
      "Epoch [23/40], Training Loss: 0.6597\n",
      "Epoch [23/40], Validation Loss: 0.6837\n",
      "Epoch [24/40], Training Loss: 0.6595\n",
      "Epoch [24/40], Validation Loss: 0.6705\n",
      "Epoch [25/40], Training Loss: 0.6579\n",
      "Epoch [25/40], Validation Loss: 0.6652\n",
      "Epoch [26/40], Training Loss: 0.6589\n",
      "Epoch [26/40], Validation Loss: 0.6620\n",
      "Epoch [27/40], Training Loss: 0.6561\n",
      "Epoch [27/40], Validation Loss: 0.6713\n",
      "Epoch [28/40], Training Loss: 0.6754\n",
      "Epoch [28/40], Validation Loss: 0.6798\n",
      "Epoch [29/40], Training Loss: 0.6860\n",
      "Epoch [29/40], Validation Loss: 0.6822\n",
      "Epoch [30/40], Training Loss: 0.6840\n",
      "Epoch [30/40], Validation Loss: 0.6915\n",
      "Epoch [31/40], Training Loss: 0.6792\n",
      "Epoch [31/40], Validation Loss: 0.6975\n",
      "Epoch [32/40], Training Loss: 0.6824\n",
      "Epoch [32/40], Validation Loss: 0.6945\n",
      "Epoch [33/40], Training Loss: 0.6813\n",
      "Epoch [33/40], Validation Loss: 0.6924\n",
      "Epoch [34/40], Training Loss: 0.6801\n",
      "Epoch [34/40], Validation Loss: 0.6933\n",
      "Epoch [35/40], Training Loss: 0.6788\n",
      "Epoch [35/40], Validation Loss: 0.6966\n",
      "Epoch [36/40], Training Loss: 0.6785\n",
      "Epoch [36/40], Validation Loss: 0.6940\n",
      "Epoch [37/40], Training Loss: 0.6795\n",
      "Epoch [37/40], Validation Loss: 0.6934\n",
      "Epoch [38/40], Training Loss: 0.6786\n",
      "Epoch [38/40], Validation Loss: 0.6953\n",
      "Epoch [39/40], Training Loss: 0.6810\n",
      "Epoch [39/40], Validation Loss: 0.6938\n",
      "Epoch [40/40], Training Loss: 0.6779\n",
      "Epoch [40/40], Validation Loss: 0.6968\n",
      "Model loss: 81.8759\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.002160933716400527, 'lstm_layers': [346, 113], 'linear_layers': [194, 110], 'dropout_layers': [0.08128172201195238]}\n",
      "Epoch [1/40], Training Loss: 0.6698\n",
      "Epoch [1/40], Validation Loss: 0.7007\n",
      "Epoch [2/40], Training Loss: 0.6150\n",
      "Epoch [2/40], Validation Loss: 0.6199\n",
      "Epoch [3/40], Training Loss: 0.5660\n",
      "Epoch [3/40], Validation Loss: 0.5839\n",
      "Epoch [4/40], Training Loss: 0.4924\n",
      "Epoch [4/40], Validation Loss: 0.5037\n",
      "Epoch [5/40], Training Loss: 0.7446\n",
      "Epoch [5/40], Validation Loss: 0.7101\n",
      "Epoch [6/40], Training Loss: 0.6875\n",
      "Epoch [6/40], Validation Loss: 0.6615\n",
      "Epoch [7/40], Training Loss: 0.6614\n",
      "Epoch [7/40], Validation Loss: 0.6545\n",
      "Epoch [8/40], Training Loss: 0.6557\n",
      "Epoch [8/40], Validation Loss: 0.6637\n",
      "Epoch [9/40], Training Loss: 0.6567\n",
      "Epoch [9/40], Validation Loss: 0.6652\n",
      "Epoch [10/40], Training Loss: 0.6522\n",
      "Epoch [10/40], Validation Loss: 0.6658\n",
      "Epoch [11/40], Training Loss: 0.6550\n",
      "Epoch [11/40], Validation Loss: 0.6664\n",
      "Epoch [12/40], Training Loss: 0.6453\n",
      "Epoch [12/40], Validation Loss: 0.6601\n",
      "Epoch [13/40], Training Loss: 0.6539\n",
      "Epoch [13/40], Validation Loss: 0.6774\n",
      "Epoch [14/40], Training Loss: 0.6501\n",
      "Epoch [14/40], Validation Loss: 0.6716\n",
      "Epoch [15/40], Training Loss: 0.6546\n",
      "Epoch [15/40], Validation Loss: 0.6697\n",
      "Epoch [16/40], Training Loss: 0.6553\n",
      "Epoch [16/40], Validation Loss: 0.6597\n",
      "Epoch [17/40], Training Loss: 0.6648\n",
      "Epoch [17/40], Validation Loss: 0.6595\n",
      "Epoch [18/40], Training Loss: 0.6504\n",
      "Epoch [18/40], Validation Loss: 0.6618\n",
      "Epoch [19/40], Training Loss: 0.6487\n",
      "Epoch [19/40], Validation Loss: 0.6634\n",
      "Epoch [20/40], Training Loss: 0.6473\n",
      "Epoch [20/40], Validation Loss: 0.6645\n",
      "Epoch [21/40], Training Loss: 0.6495\n",
      "Epoch [21/40], Validation Loss: 0.6625\n",
      "Epoch [22/40], Training Loss: 0.6484\n",
      "Epoch [22/40], Validation Loss: 0.6616\n",
      "Epoch [23/40], Training Loss: 0.6468\n",
      "Epoch [23/40], Validation Loss: 0.6697\n",
      "Epoch [24/40], Training Loss: 0.6459\n",
      "Epoch [24/40], Validation Loss: 0.6729\n",
      "Epoch [25/40], Training Loss: 0.6440\n",
      "Epoch [25/40], Validation Loss: 0.6621\n",
      "Epoch [26/40], Training Loss: 0.6415\n",
      "Epoch [26/40], Validation Loss: 0.6929\n",
      "Epoch [27/40], Training Loss: 0.6399\n",
      "Epoch [27/40], Validation Loss: 0.6921\n",
      "Epoch [28/40], Training Loss: 0.6360\n",
      "Epoch [28/40], Validation Loss: 0.6852\n",
      "Epoch [29/40], Training Loss: 0.6319\n",
      "Epoch [29/40], Validation Loss: 0.6878\n",
      "Epoch [30/40], Training Loss: 0.6325\n",
      "Epoch [30/40], Validation Loss: 0.6912\n",
      "Epoch [31/40], Training Loss: 0.6369\n",
      "Epoch [31/40], Validation Loss: 0.6946\n",
      "Epoch [32/40], Training Loss: 0.6552\n",
      "Epoch [32/40], Validation Loss: 0.6758\n",
      "Epoch [33/40], Training Loss: 0.6646\n",
      "Epoch [33/40], Validation Loss: 0.6688\n",
      "Epoch [34/40], Training Loss: 0.6527\n",
      "Epoch [34/40], Validation Loss: 0.6774\n",
      "Epoch [35/40], Training Loss: 0.6459\n",
      "Epoch [35/40], Validation Loss: 0.6720\n",
      "Epoch [36/40], Training Loss: 0.6447\n",
      "Epoch [36/40], Validation Loss: 0.6474\n",
      "Epoch [37/40], Training Loss: 0.6361\n",
      "Epoch [37/40], Validation Loss: 0.7003\n",
      "Epoch [38/40], Training Loss: 0.6525\n",
      "Epoch [38/40], Validation Loss: 0.6757\n",
      "Epoch [39/40], Training Loss: 0.6571\n",
      "Epoch [39/40], Validation Loss: 0.6704\n",
      "Epoch [40/40], Training Loss: 0.6555\n",
      "Epoch [40/40], Validation Loss: 0.6800\n",
      "Model loss: 79.9928\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.002201349636628736, 'lstm_layers': [205, 96], 'linear_layers': [183, 113], 'dropout_layers': [0.07267275348780074]}\n",
      "Epoch [1/40], Training Loss: 0.6965\n",
      "Epoch [1/40], Validation Loss: 0.6899\n",
      "Epoch [2/40], Training Loss: 0.6547\n",
      "Epoch [2/40], Validation Loss: 0.6534\n",
      "Epoch [3/40], Training Loss: 0.5475\n",
      "Epoch [3/40], Validation Loss: 0.5762\n",
      "Epoch [4/40], Training Loss: 0.4687\n",
      "Epoch [4/40], Validation Loss: 0.4866\n",
      "Epoch [5/40], Training Loss: 0.7508\n",
      "Epoch [5/40], Validation Loss: 0.6653\n",
      "Epoch [6/40], Training Loss: 0.6457\n",
      "Epoch [6/40], Validation Loss: 0.7100\n",
      "Epoch [7/40], Training Loss: 0.6452\n",
      "Epoch [7/40], Validation Loss: 0.6558\n",
      "Epoch [8/40], Training Loss: 0.6401\n",
      "Epoch [8/40], Validation Loss: 0.6476\n",
      "Epoch [9/40], Training Loss: 0.6452\n",
      "Epoch [9/40], Validation Loss: 0.6323\n",
      "Epoch [10/40], Training Loss: 0.6488\n",
      "Epoch [10/40], Validation Loss: 0.6479\n",
      "Epoch [11/40], Training Loss: 0.6329\n",
      "Epoch [11/40], Validation Loss: 0.6223\n",
      "Epoch [12/40], Training Loss: 0.6314\n",
      "Epoch [12/40], Validation Loss: 0.6382\n",
      "Epoch [13/40], Training Loss: 0.6546\n",
      "Epoch [13/40], Validation Loss: 0.7315\n",
      "Epoch [14/40], Training Loss: 0.6400\n",
      "Epoch [14/40], Validation Loss: 0.6915\n",
      "Epoch [15/40], Training Loss: 0.6233\n",
      "Epoch [15/40], Validation Loss: 0.6223\n",
      "Epoch [16/40], Training Loss: 0.6214\n",
      "Epoch [16/40], Validation Loss: 0.6312\n",
      "Epoch [17/40], Training Loss: 0.6221\n",
      "Epoch [17/40], Validation Loss: 0.6441\n",
      "Epoch [18/40], Training Loss: 0.6200\n",
      "Epoch [18/40], Validation Loss: 0.6486\n",
      "Epoch [19/40], Training Loss: 0.6192\n",
      "Epoch [19/40], Validation Loss: 0.6498\n",
      "Epoch [20/40], Training Loss: 0.6175\n",
      "Epoch [20/40], Validation Loss: 0.6422\n",
      "Epoch [21/40], Training Loss: 0.6213\n",
      "Epoch [21/40], Validation Loss: 0.6286\n",
      "Epoch [22/40], Training Loss: 0.6180\n",
      "Epoch [22/40], Validation Loss: 0.6281\n",
      "Epoch [23/40], Training Loss: 0.6175\n",
      "Epoch [23/40], Validation Loss: 0.6263\n",
      "Epoch [24/40], Training Loss: 0.6180\n",
      "Epoch [24/40], Validation Loss: 0.6215\n",
      "Epoch [25/40], Training Loss: 0.6153\n",
      "Epoch [25/40], Validation Loss: 0.6712\n",
      "Epoch [26/40], Training Loss: 0.6088\n",
      "Epoch [26/40], Validation Loss: 0.6702\n",
      "Epoch [27/40], Training Loss: 0.6105\n",
      "Epoch [27/40], Validation Loss: 0.6782\n",
      "Epoch [28/40], Training Loss: 0.6082\n",
      "Epoch [28/40], Validation Loss: 0.6858\n",
      "Epoch [29/40], Training Loss: 0.6131\n",
      "Epoch [29/40], Validation Loss: 0.6730\n",
      "Epoch [30/40], Training Loss: 0.6085\n",
      "Epoch [30/40], Validation Loss: 0.6830\n",
      "Epoch [31/40], Training Loss: 0.6091\n",
      "Epoch [31/40], Validation Loss: 0.6588\n",
      "Epoch [32/40], Training Loss: 0.6135\n",
      "Epoch [32/40], Validation Loss: 0.6656\n",
      "Epoch [33/40], Training Loss: 0.6094\n",
      "Epoch [33/40], Validation Loss: 0.6571\n",
      "Epoch [34/40], Training Loss: 0.6128\n",
      "Epoch [34/40], Validation Loss: 0.6567\n",
      "Epoch [35/40], Training Loss: 0.6086\n",
      "Epoch [35/40], Validation Loss: 0.6620\n",
      "Epoch [36/40], Training Loss: 0.6121\n",
      "Epoch [36/40], Validation Loss: 0.6663\n",
      "Epoch [37/40], Training Loss: 0.6140\n",
      "Epoch [37/40], Validation Loss: 0.6634\n",
      "Epoch [38/40], Training Loss: 0.6111\n",
      "Epoch [38/40], Validation Loss: 0.6638\n",
      "Epoch [39/40], Training Loss: 0.6135\n",
      "Epoch [39/40], Validation Loss: 0.6532\n",
      "Epoch [40/40], Training Loss: 0.6092\n",
      "Epoch [40/40], Validation Loss: 0.6693\n",
      "Model loss: 79.9361\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.005173801576084079, 'lstm_layers': [321, 89], 'linear_layers': [129, 139], 'dropout_layers': [0.09078454550051902]}\n",
      "Epoch [1/40], Training Loss: 0.7127\n",
      "Epoch [1/40], Validation Loss: 0.6903\n",
      "Epoch [2/40], Training Loss: 0.6850\n",
      "Epoch [2/40], Validation Loss: 0.7199\n",
      "Epoch [3/40], Training Loss: 0.6774\n",
      "Epoch [3/40], Validation Loss: 0.6853\n",
      "Epoch [4/40], Training Loss: 0.6812\n",
      "Epoch [4/40], Validation Loss: 0.6913\n",
      "Epoch [5/40], Training Loss: 0.6837\n",
      "Epoch [5/40], Validation Loss: 0.6917\n",
      "Epoch [6/40], Training Loss: 0.6819\n",
      "Epoch [6/40], Validation Loss: 0.7061\n",
      "Epoch [7/40], Training Loss: 0.6805\n",
      "Epoch [7/40], Validation Loss: 0.6916\n",
      "Epoch [8/40], Training Loss: 0.6818\n",
      "Epoch [8/40], Validation Loss: 0.6918\n",
      "Epoch [9/40], Training Loss: 0.6800\n",
      "Epoch [9/40], Validation Loss: 0.6960\n",
      "Epoch [10/40], Training Loss: 0.6796\n",
      "Epoch [10/40], Validation Loss: 0.6939\n",
      "Epoch [11/40], Training Loss: 0.6791\n",
      "Epoch [11/40], Validation Loss: 0.6971\n",
      "Epoch [12/40], Training Loss: 0.6815\n",
      "Epoch [12/40], Validation Loss: 0.6953\n",
      "Epoch [13/40], Training Loss: 0.6811\n",
      "Epoch [13/40], Validation Loss: 0.6973\n",
      "Epoch [14/40], Training Loss: 0.6769\n",
      "Epoch [14/40], Validation Loss: 0.6921\n",
      "Epoch [15/40], Training Loss: 0.6829\n",
      "Epoch [15/40], Validation Loss: 0.6994\n",
      "Epoch [16/40], Training Loss: 0.6775\n",
      "Epoch [16/40], Validation Loss: 0.7053\n",
      "Epoch [17/40], Training Loss: 0.6737\n",
      "Epoch [17/40], Validation Loss: 0.6951\n",
      "Epoch [18/40], Training Loss: 0.6763\n",
      "Epoch [18/40], Validation Loss: 0.7036\n",
      "Epoch [19/40], Training Loss: 0.6767\n",
      "Epoch [19/40], Validation Loss: 0.7022\n",
      "Epoch [20/40], Training Loss: 0.6770\n",
      "Epoch [20/40], Validation Loss: 0.7100\n",
      "Epoch [21/40], Training Loss: 0.6747\n",
      "Epoch [21/40], Validation Loss: 0.7004\n",
      "Epoch [22/40], Training Loss: 0.6748\n",
      "Epoch [22/40], Validation Loss: 0.6954\n",
      "Epoch [23/40], Training Loss: 0.6733\n",
      "Epoch [23/40], Validation Loss: 0.6994\n",
      "Epoch [24/40], Training Loss: 0.6776\n",
      "Epoch [24/40], Validation Loss: 0.6959\n",
      "Epoch [25/40], Training Loss: 0.6735\n",
      "Epoch [25/40], Validation Loss: 0.7031\n",
      "Epoch [26/40], Training Loss: 0.6739\n",
      "Epoch [26/40], Validation Loss: 0.6941\n",
      "Epoch [27/40], Training Loss: 0.6742\n",
      "Epoch [27/40], Validation Loss: 0.6929\n",
      "Epoch [28/40], Training Loss: 0.6760\n",
      "Epoch [28/40], Validation Loss: 0.6960\n",
      "Epoch [29/40], Training Loss: 0.6730\n",
      "Epoch [29/40], Validation Loss: 0.7005\n",
      "Epoch [30/40], Training Loss: 0.6749\n",
      "Epoch [30/40], Validation Loss: 0.6942\n",
      "Epoch [31/40], Training Loss: 0.6740\n",
      "Epoch [31/40], Validation Loss: 0.7012\n",
      "Epoch [32/40], Training Loss: 0.6758\n",
      "Epoch [32/40], Validation Loss: 0.6983\n",
      "Epoch [33/40], Training Loss: 0.6750\n",
      "Epoch [33/40], Validation Loss: 0.6971\n",
      "Epoch [34/40], Training Loss: 0.6743\n",
      "Epoch [34/40], Validation Loss: 0.7028\n",
      "Epoch [35/40], Training Loss: 0.6752\n",
      "Epoch [35/40], Validation Loss: 0.7004\n",
      "Epoch [36/40], Training Loss: 0.6766\n",
      "Epoch [36/40], Validation Loss: 0.6954\n",
      "Epoch [37/40], Training Loss: 0.6739\n",
      "Epoch [37/40], Validation Loss: 0.6945\n",
      "Epoch [38/40], Training Loss: 0.6723\n",
      "Epoch [38/40], Validation Loss: 0.6957\n",
      "Epoch [39/40], Training Loss: 0.6722\n",
      "Epoch [39/40], Validation Loss: 0.6949\n",
      "Epoch [40/40], Training Loss: 0.6748\n",
      "Epoch [40/40], Validation Loss: 0.6991\n",
      "Model loss: 79.7322\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.008334956498926755, 'lstm_layers': [224, 104], 'linear_layers': [183, 117], 'dropout_layers': [0.07370262891266759]}\n",
      "Epoch [1/40], Training Loss: 0.7099\n",
      "Epoch [1/40], Validation Loss: 0.7254\n",
      "Epoch [2/40], Training Loss: 0.6783\n",
      "Epoch [2/40], Validation Loss: 0.6937\n",
      "Epoch [3/40], Training Loss: 0.5880\n",
      "Epoch [3/40], Validation Loss: 0.7121\n",
      "Epoch [4/40], Training Loss: 0.6953\n",
      "Epoch [4/40], Validation Loss: 0.6361\n",
      "Epoch [5/40], Training Loss: 0.6283\n",
      "Epoch [5/40], Validation Loss: 0.6236\n",
      "Epoch [6/40], Training Loss: 0.6376\n",
      "Epoch [6/40], Validation Loss: 0.6771\n",
      "Epoch [7/40], Training Loss: 0.6315\n",
      "Epoch [7/40], Validation Loss: 0.6581\n",
      "Epoch [8/40], Training Loss: 0.7049\n",
      "Epoch [8/40], Validation Loss: 0.6854\n",
      "Epoch [9/40], Training Loss: 0.6876\n",
      "Epoch [9/40], Validation Loss: 0.7135\n",
      "Epoch [10/40], Training Loss: 0.6897\n",
      "Epoch [10/40], Validation Loss: 0.6705\n",
      "Epoch [11/40], Training Loss: 0.6855\n",
      "Epoch [11/40], Validation Loss: 0.6701\n",
      "Epoch [12/40], Training Loss: 0.6798\n",
      "Epoch [12/40], Validation Loss: 0.6630\n",
      "Epoch [13/40], Training Loss: 0.6484\n",
      "Epoch [13/40], Validation Loss: 0.6356\n",
      "Epoch [14/40], Training Loss: 0.6602\n",
      "Epoch [14/40], Validation Loss: 0.6592\n",
      "Epoch [15/40], Training Loss: 0.6521\n",
      "Epoch [15/40], Validation Loss: 0.6766\n",
      "Epoch [16/40], Training Loss: 0.6431\n",
      "Epoch [16/40], Validation Loss: 0.6502\n",
      "Epoch [17/40], Training Loss: 0.6342\n",
      "Epoch [17/40], Validation Loss: 0.6361\n",
      "Epoch [18/40], Training Loss: 0.6550\n",
      "Epoch [18/40], Validation Loss: 0.6404\n",
      "Epoch [19/40], Training Loss: 0.6596\n",
      "Epoch [19/40], Validation Loss: 0.6478\n",
      "Epoch [20/40], Training Loss: 0.6596\n",
      "Epoch [20/40], Validation Loss: 0.6516\n",
      "Epoch [21/40], Training Loss: 0.6596\n",
      "Epoch [21/40], Validation Loss: 0.6604\n",
      "Epoch [22/40], Training Loss: 0.6505\n",
      "Epoch [22/40], Validation Loss: 0.6612\n",
      "Epoch [23/40], Training Loss: 0.6552\n",
      "Epoch [23/40], Validation Loss: 0.6673\n",
      "Epoch [24/40], Training Loss: 0.6474\n",
      "Epoch [24/40], Validation Loss: 0.6561\n",
      "Epoch [25/40], Training Loss: 0.6418\n",
      "Epoch [25/40], Validation Loss: 0.6582\n",
      "Epoch [26/40], Training Loss: 0.6612\n",
      "Epoch [26/40], Validation Loss: 0.6698\n",
      "Epoch [27/40], Training Loss: 0.6679\n",
      "Epoch [27/40], Validation Loss: 0.6493\n",
      "Epoch [28/40], Training Loss: 0.6599\n",
      "Epoch [28/40], Validation Loss: 0.6516\n",
      "Epoch [29/40], Training Loss: 0.6641\n",
      "Epoch [29/40], Validation Loss: 0.6538\n",
      "Epoch [30/40], Training Loss: 0.6607\n",
      "Epoch [30/40], Validation Loss: 0.6526\n",
      "Epoch [31/40], Training Loss: 0.6593\n",
      "Epoch [31/40], Validation Loss: 0.6508\n",
      "Epoch [32/40], Training Loss: 0.6587\n",
      "Epoch [32/40], Validation Loss: 0.6515\n",
      "Epoch [33/40], Training Loss: 0.6562\n",
      "Epoch [33/40], Validation Loss: 0.6501\n",
      "Epoch [34/40], Training Loss: 0.6568\n",
      "Epoch [34/40], Validation Loss: 0.6530\n",
      "Epoch [35/40], Training Loss: 0.6580\n",
      "Epoch [35/40], Validation Loss: 0.6534\n",
      "Epoch [36/40], Training Loss: 0.6639\n",
      "Epoch [36/40], Validation Loss: 0.6579\n",
      "Epoch [37/40], Training Loss: 0.6586\n",
      "Epoch [37/40], Validation Loss: 0.6521\n",
      "Epoch [38/40], Training Loss: 0.6623\n",
      "Epoch [38/40], Validation Loss: 0.6566\n",
      "Epoch [39/40], Training Loss: 0.6587\n",
      "Epoch [39/40], Validation Loss: 0.6508\n",
      "Epoch [40/40], Training Loss: 0.6571\n",
      "Epoch [40/40], Validation Loss: 0.6497\n",
      "Model loss: 83.1765\n",
      "{'batch_size': 16, 'criterion': BCEWithLogitsLoss(), 'epochs': 40, 'init': <function xavier_normal_ at 0x10d3742c0>, 'input_size': 4, 'lstm_activation': <function tanh at 0x10d1de160>, 'linear_activation': <function relu at 0x10d1dd760>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d1de200>, 'lr': 0.0037499214970629605, 'lstm_layers': [282, 84], 'linear_layers': [136, 144], 'dropout_layers': [0.06690232054532178]}\n",
      "Epoch [1/40], Training Loss: 0.6743\n",
      "Epoch [1/40], Validation Loss: 0.6521\n",
      "Epoch [2/40], Training Loss: 0.6588\n",
      "Epoch [2/40], Validation Loss: 0.6600\n",
      "Epoch [3/40], Training Loss: 0.6535\n",
      "Epoch [3/40], Validation Loss: 0.7123\n",
      "Epoch [4/40], Training Loss: 0.6553\n",
      "Epoch [4/40], Validation Loss: 0.6727\n",
      "Epoch [5/40], Training Loss: 0.6725\n",
      "Epoch [5/40], Validation Loss: 0.6675\n",
      "Epoch [6/40], Training Loss: 0.6548\n",
      "Epoch [6/40], Validation Loss: 0.6702\n",
      "Epoch [7/40], Training Loss: 0.6512\n",
      "Epoch [7/40], Validation Loss: 0.6559\n",
      "Epoch [8/40], Training Loss: 0.6575\n",
      "Epoch [8/40], Validation Loss: 0.6590\n",
      "Epoch [9/40], Training Loss: 0.6541\n",
      "Epoch [9/40], Validation Loss: 0.6659\n",
      "Epoch [10/40], Training Loss: 0.6589\n",
      "Epoch [10/40], Validation Loss: 0.6635\n",
      "Epoch [11/40], Training Loss: 0.6622\n",
      "Epoch [11/40], Validation Loss: 0.6741\n",
      "Epoch [12/40], Training Loss: 0.6555\n",
      "Epoch [12/40], Validation Loss: 0.6671\n",
      "Epoch [13/40], Training Loss: 0.6561\n",
      "Epoch [13/40], Validation Loss: 0.6578\n",
      "Epoch [14/40], Training Loss: 0.6554\n",
      "Epoch [14/40], Validation Loss: 0.6592\n",
      "Epoch [15/40], Training Loss: 0.6554\n",
      "Epoch [15/40], Validation Loss: 0.6649\n",
      "Epoch [16/40], Training Loss: 0.6660\n",
      "Epoch [16/40], Validation Loss: 0.6378\n",
      "Epoch [17/40], Training Loss: 0.6796\n",
      "Epoch [17/40], Validation Loss: 0.6868\n",
      "Epoch [18/40], Training Loss: 0.6790\n",
      "Epoch [18/40], Validation Loss: 0.6915\n",
      "Epoch [19/40], Training Loss: 0.6778\n",
      "Epoch [19/40], Validation Loss: 0.6900\n",
      "Epoch [20/40], Training Loss: 0.6772\n",
      "Epoch [20/40], Validation Loss: 0.6888\n",
      "Epoch [21/40], Training Loss: 0.6791\n",
      "Epoch [21/40], Validation Loss: 0.6939\n",
      "Epoch [22/40], Training Loss: 0.6778\n",
      "Epoch [22/40], Validation Loss: 0.6865\n",
      "Epoch [23/40], Training Loss: 0.6787\n",
      "Epoch [23/40], Validation Loss: 0.6887\n",
      "Epoch [24/40], Training Loss: 0.6762\n",
      "Epoch [24/40], Validation Loss: 0.6884\n",
      "Epoch [25/40], Training Loss: 0.6753\n",
      "Epoch [25/40], Validation Loss: 0.6885\n",
      "Epoch [26/40], Training Loss: 0.6745\n",
      "Epoch [26/40], Validation Loss: 0.6873\n",
      "Epoch [27/40], Training Loss: 0.6739\n",
      "Epoch [27/40], Validation Loss: 0.6880\n",
      "Epoch [28/40], Training Loss: 0.6736\n",
      "Epoch [28/40], Validation Loss: 0.6879\n",
      "Epoch [29/40], Training Loss: 0.6734\n",
      "Epoch [29/40], Validation Loss: 0.6864\n",
      "Epoch [30/40], Training Loss: 0.6846\n",
      "Epoch [30/40], Validation Loss: 0.6787\n",
      "Epoch [31/40], Training Loss: 0.6798\n",
      "Epoch [31/40], Validation Loss: 0.6874\n",
      "Epoch [32/40], Training Loss: 0.6822\n",
      "Epoch [32/40], Validation Loss: 0.6948\n",
      "Epoch [33/40], Training Loss: 0.6796\n",
      "Epoch [33/40], Validation Loss: 0.6916\n",
      "Epoch [34/40], Training Loss: 0.6775\n",
      "Epoch [34/40], Validation Loss: 0.6936\n",
      "Epoch [35/40], Training Loss: 0.6779\n",
      "Epoch [35/40], Validation Loss: 0.6959\n",
      "Epoch [36/40], Training Loss: 0.6777\n",
      "Epoch [36/40], Validation Loss: 0.6937\n",
      "Epoch [37/40], Training Loss: 0.6781\n",
      "Epoch [37/40], Validation Loss: 0.6918\n",
      "Epoch [38/40], Training Loss: 0.6775\n",
      "Epoch [38/40], Validation Loss: 0.6923\n",
      "Epoch [39/40], Training Loss: 0.6772\n",
      "Epoch [39/40], Validation Loss: 0.6895\n",
      "Epoch [40/40], Training Loss: 0.6790\n",
      "Epoch [40/40], Validation Loss: 0.6877\n",
      "Model loss: 82.2499\n"
     ]
    }
   ],
   "source": [
    "JTEXT_LOW = PlasmaDataset(org_directory = ORG_DATA_DIR, h5_source = HDF5_DATA_DIR)\n",
    "MODELER = PlasmaModel(MODEL_DIR, static_parameters=STATIC_PARAMETERS, json_save_file=MODEL_METRICS)\n",
    "makeDataset(JTEXT_LOW, split=DATA_SPLIT, frac=DATA_FRAC, features=FEATS)\n",
    "makeModels(\n",
    "    modeler=MODELER,\n",
    "    processed_data=PROCESSED_DATA,\n",
    "    parameter_ranges=PARAMETER_RANGES,\n",
    "    static_parameters=STATIC_PARAMETERS,\n",
    "    model_count=MODEL_COUNT,\n",
    "    searchmode=HP_SEARCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aaf84f-f89a-4be2-b00d-9b962dff56b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
