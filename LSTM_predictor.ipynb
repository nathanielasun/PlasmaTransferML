{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe7b3d1-5e35-4160-8aba-327467e6639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PD.PlasmaDataset import PlasmaDataset\n",
    "from PML.PlasmaModel import PlasmaModel\n",
    "from PML.PMLParameters import PMLParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3877660-dae5-46a9-8097-9b62c550e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT = [0.5, 0.2, 0.3] #train/test/val splits\n",
    "DATA_FRAC = 1 #fraction of files to load data from\n",
    "DATASET_NAME = \"main\"\n",
    "HDF5_DATA_DIR = \"./jtext_data/low_freq\" #data to source hdf5 files from\n",
    "ORG_DATA_DIR = \"./jtext_org\" #directory for exporting data CSVs\n",
    "MODEL_COUNT = 5 #number of models to randomly generate and train\n",
    "MODEL_DIR = \"./models\" #directory to save trained models\n",
    "MODEL_METRICS = \"./models/metrics.json\"\n",
    "FEATS = ['dx', 'dy', 'Iohp', 'ip', 'ip_error'] #model features\n",
    "HP_SEARCH = 'random' #hyperparameter search mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ce6538-176d-4b75-bfdd-7a825e70a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize processed data with some dummy training feature data directories for testing (uses dx and dy features)\n",
    "PROCESSED_DATA = {\n",
    "    \"train_norm\"   : f'./jtext_org/train/train-norm-{DATASET_NAME}.csv',\n",
    "    \"train_labels\" : f'./jtext_org/train/train-labels-{DATASET_NAME}.csv',\n",
    "    \"test_norm\"    : f'./jtext_org/test/test-norm-{DATASET_NAME}.csv',\n",
    "    \"test_labels\"  : f'./jtext_org/test/test-labels-{DATASET_NAME}.csv',\n",
    "    \"val_norm\"     : f'./jtext_org/val/val-norm-{DATASET_NAME}.csv',\n",
    "    \"val_labels\"   : f'./jtext_org/val/val-labels-{DATASET_NAME}.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a063378-18a1-4747-9d3b-98ff3888c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#designate feature ranges and static parameters for hyperparameter search\n",
    "#note to current user - grid search is currently borked - don't use (plus not efficient)\n",
    "PARAMETER_RANGES = {\n",
    "    'lr'            : [0.001, 0.01], #learning rate range\n",
    "    'lstm_layers'   : [[200,400], [80,120]], #lstm layer count and hidden size ranges\n",
    "    'linear_layers' : [[100,200], [100,150]], #linear layer count and neuron ranges\n",
    "    'dropout_layers': [[0.05, 0.1]], #dropout layer count and dropout probabilities\n",
    "}\n",
    "STATIC_PARAMETERS = {\n",
    "    'batch_size'       : 4,\n",
    "    'criterion'        : torch.nn.BCEWithLogitsLoss(), #uses binary cross entropy loss\n",
    "    'epochs'           : 2, #number of training epochs/model\n",
    "    'init'             : torch.nn.init.xavier_normal_,\n",
    "    'input_size'       : len(FEATS), #set input size to # of features\n",
    "    'lstm_activation'  : torch.nn.functional.tanh, #LSTM layers activation function\n",
    "    'linear_activation': torch.nn.functional.relu, #Linear layers activation function\n",
    "    'optimizer'        : torch.optim.Adam, #use ADAM optimizer\n",
    "    'output_activation': torch.nn.functional.sigmoid, #output neuron activation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6cbd47-38c8-4649-8f4c-24e676289e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(dataset:\"PlasmaDataset\", split:list, features:list, frac:float=1, preview=False):\n",
    "    dataset.initialize() #creates train/test/val subdatasets\n",
    "    dataset.sourceFiles(data_split = split, data_frac = frac) #initialize split/datafrac and gather hdf5 file info\n",
    "    dataset.sourceData(features) #source specified feature data from files\n",
    "    dataset.calcStats() #calculate data statistics from raw feature data\n",
    "    dataset.normalize() #use data statistics to normalize data\n",
    "    dataset.saveCSV(['train', 'test', 'val', 'stats'], name=DATASET_NAME) #export dataset to model-loadable CSV\n",
    "    if preview:\n",
    "        dataset.preview() #preview datasets\n",
    "    dataset.deleteDatasets() #remove dataset from memory (since saved to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51df6cae-7e5b-458f-8b1f-0f65cab2513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModels(\n",
    "                modeler:\"PlasmaModel\", \n",
    "                processed_data:dict, \n",
    "                parameter_ranges:dict, \n",
    "                static_parameters:dict, \n",
    "                model_count:int, \n",
    "                searchmode:str\n",
    "              ):\n",
    "    modeler.makeHyperparameterSet(\n",
    "                    static_params=static_parameters, \n",
    "                    param_ranges=parameter_ranges, \n",
    "                    count=model_count, \n",
    "                    mode=searchmode\n",
    "    )\n",
    "    modeler.prepareData(processed_data)\n",
    "    modeler.runModelSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e97a930-2ec4-4e6c-b85d-25a16d421b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4, 'criterion': BCEWithLogitsLoss(), 'epochs': 2, 'init': <function xavier_normal_ at 0x10db745e0>, 'input_size': 5, 'lstm_activation': <function tanh at 0x10d9de480>, 'linear_activation': <function relu at 0x10d9dda80>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d9de520>, 'lr': 0.0019371741067206662, 'lstm_layers': [388, 101], 'linear_layers': [198, 121], 'dropout_layers': [0.09623629749578264]}\n",
      "Epoch [1/2], Training Loss: 0.6875\n",
      "Epoch [1/2], Validation Loss: 0.6663\n",
      "Epoch [2/2], Training Loss: 0.6742\n",
      "Epoch [2/2], Validation Loss: 0.6374\n",
      "Model loss: 72.6928\n",
      "{'batch_size': 4, 'criterion': BCEWithLogitsLoss(), 'epochs': 2, 'init': <function xavier_normal_ at 0x10db745e0>, 'input_size': 5, 'lstm_activation': <function tanh at 0x10d9de480>, 'linear_activation': <function relu at 0x10d9dda80>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d9de520>, 'lr': 0.008412372937363148, 'lstm_layers': [340, 87], 'linear_layers': [134, 144], 'dropout_layers': [0.05616810485141623]}\n",
      "Epoch [1/2], Training Loss: 0.7020\n",
      "Epoch [1/2], Validation Loss: 0.6903\n",
      "Epoch [2/2], Training Loss: 0.6937\n",
      "Epoch [2/2], Validation Loss: 0.6932\n",
      "Model loss: 80.4257\n",
      "{'batch_size': 4, 'criterion': BCEWithLogitsLoss(), 'epochs': 2, 'init': <function xavier_normal_ at 0x10db745e0>, 'input_size': 5, 'lstm_activation': <function tanh at 0x10d9de480>, 'linear_activation': <function relu at 0x10d9dda80>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d9de520>, 'lr': 0.007776975783488083, 'lstm_layers': [266, 94], 'linear_layers': [110, 107], 'dropout_layers': [0.08986864973728811]}\n",
      "Epoch [1/2], Training Loss: 0.7153\n",
      "Epoch [1/2], Validation Loss: 0.6891\n",
      "Epoch [2/2], Training Loss: 0.6946\n",
      "Epoch [2/2], Validation Loss: 0.6911\n",
      "Model loss: 78.3367\n",
      "{'batch_size': 4, 'criterion': BCEWithLogitsLoss(), 'epochs': 2, 'init': <function xavier_normal_ at 0x10db745e0>, 'input_size': 5, 'lstm_activation': <function tanh at 0x10d9de480>, 'linear_activation': <function relu at 0x10d9dda80>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d9de520>, 'lr': 0.009871894334764129, 'lstm_layers': [300, 87], 'linear_layers': [112, 110], 'dropout_layers': [0.059015664651224625]}\n",
      "Epoch [1/2], Training Loss: 0.7081\n",
      "Epoch [1/2], Validation Loss: 0.6867\n",
      "Epoch [2/2], Training Loss: 0.6926\n",
      "Epoch [2/2], Validation Loss: 0.6867\n",
      "Model loss: 78.8069\n",
      "{'batch_size': 4, 'criterion': BCEWithLogitsLoss(), 'epochs': 2, 'init': <function xavier_normal_ at 0x10db745e0>, 'input_size': 5, 'lstm_activation': <function tanh at 0x10d9de480>, 'linear_activation': <function relu at 0x10d9dda80>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'output_activation': <function sigmoid at 0x10d9de520>, 'lr': 0.00840567366803142, 'lstm_layers': [266, 90], 'linear_layers': [199, 128], 'dropout_layers': [0.05867593843176492]}\n",
      "Epoch [1/2], Training Loss: 0.6998\n",
      "Epoch [1/2], Validation Loss: 0.6866\n",
      "Epoch [2/2], Training Loss: 0.6893\n",
      "Epoch [2/2], Validation Loss: 0.6897\n",
      "Model loss: 78.2953\n"
     ]
    }
   ],
   "source": [
    "JTEXT_LOW = PlasmaDataset(org_directory = ORG_DATA_DIR, h5_source = HDF5_DATA_DIR)\n",
    "MODELER = PlasmaModel(MODEL_DIR, static_parameters=STATIC_PARAMETERS, json_save_file=MODEL_METRICS)\n",
    "makeDataset(JTEXT_LOW, split=DATA_SPLIT, frac=DATA_FRAC, features=FEATS)\n",
    "makeModels(\n",
    "    modeler=MODELER,\n",
    "    processed_data=PROCESSED_DATA,\n",
    "    parameter_ranges=PARAMETER_RANGES,\n",
    "    static_parameters=STATIC_PARAMETERS,\n",
    "    model_count=MODEL_COUNT,\n",
    "    searchmode=HP_SEARCH\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
